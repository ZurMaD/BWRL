{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entregable_Avance_BipedalWalker.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZurMaD/BWRL/blob/master/Entregable_Avance_BipedalWalker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fz49jy4qdvL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Desarrollo y Comparación de Algoritmos de Aprendizaje por Refuerzo en Entorno Estocástico OpeanAI para Locomoción de un Bípedo en 2D.\n",
        "\n",
        "---\n",
        "\n",
        "@Autores: Díaz P., Lizano D., Villena A., Zegarra D.\n",
        "@Última moficación: 15/05/19\n",
        "\n",
        "## Resumen.-\n",
        "El estudio tiene como fin crear un agente que supere obstáculos en el menor tiempo posible para una posterior implementación en robots rescatistas no tripulados. Este documento presenta una comparación entre algoritmos de aprendizaje por refuerzo que son capaces de superar el desafío Bipedal-Walker-Hardcore-v2 en el entorno de simulación OpenAI-Gym.\n",
        "\n",
        "## Índice.-\n",
        "\n",
        "<table align=\"left\">\n",
        "  <tr>\n",
        "    <th>N°</th>\n",
        "    <th>Título</th>\n",
        "    <th>Descripción</th> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Adaptando el entorno</td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>2</td>\n",
        "    <td>Heuristica</td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>3</td>\n",
        "    <td>DDPG</td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>4</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>7</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>8</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>9</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>10</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>11</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>12</td>\n",
        "    <td></td> \n",
        "    <td></td> \n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8PNIy-OwMh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#  Análisis \n",
        "\n",
        "---\n",
        "\n",
        "En análisis que se llevará a cabo es el de comparar algoritmos de aprendizaje por refuerzo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzecRp6dqSmS",
        "colab_type": "text"
      },
      "source": [
        "## 1 ) Generamos el entorno para guardar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOUth3-kqcvB",
        "colab_type": "text"
      },
      "source": [
        "Instalación de un display virtual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b972OCa5nDpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfIdfTQ7nEpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d1uHjWWnF5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOGwRKlfnG0K",
        "colab_type": "code",
        "outputId": "590a15d8-47fc-4cbf-ce3e-9fc04de9c638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 600))\n",
        "display.start()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x600x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x600x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYhYFXp0oq2e",
        "colab_type": "code",
        "outputId": "c2e2ddee-8b0b-4ad6-b9bf-d97c42220565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting box2d-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "\u001b[33m  WARNING: gym 0.10.11 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.16.3)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvv06nNPvzDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# idea from\n",
        "# https://stackoverflow.com/questions/34975972/how-can-i-make-a-video-from-array-of-images-in-matplotlib\n",
        "i=1\n",
        "def deleter(num_files=100):\n",
        "  try:\n",
        "    for i in range(num_files):\n",
        "      os.system(str(\"rm /content/img%02d.png\" % i))\n",
        "      if i%50==0:\n",
        "        print(\"deleter: Se ha borrado hasta la img\",i)\n",
        "    print(\"deleter: Se ha borrado hasta la img\",i+1)\n",
        "  except Exception as e:\n",
        "    print(\"deleter\",e)\n",
        "    print(\"deleter: Algo salió mal en deleter\")\n",
        "    pass\n",
        "  #print(\"video_generado.mp4 Borrado\")\n",
        "     \n",
        "def generate_video(video,file_name):\n",
        "  try:\n",
        "    for i in range(len(video)):\n",
        "      plt.imshow(video[i])\n",
        "      plt.savefig(\"/content/img%02d.png\" % i)\n",
        "      if i%10==0:\n",
        "        print(\"generate_video: Se ha generado hasta la img\",i,\"/\",len(video))\n",
        "    print(\"generate_video: Se ha generado hasta la img\",i+1,\"/\",len(video))\n",
        "  except Exception as e:\n",
        "    print(\"generate_video\",e)\n",
        "    print(\"generate_video: Algo salió mal en generate_video\")\n",
        "    pass\n",
        "  \n",
        "  os.system(\"rm /content/\"+file_name+\".mp4\")\n",
        "  \n",
        "  \n",
        "  print(\"generate_video: Generando video...\")\n",
        "  subprocess.call([\n",
        "      'ffmpeg', '-framerate', '8', '-i', '/content/img%02d.png', '-r', '30', '-pix_fmt', 'yuv420p'\n",
        "      , file_name+'.mp4'\n",
        "  ])\n",
        "  \n",
        "\n",
        "#deleter(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLWodlzOqDbi",
        "colab_type": "text"
      },
      "source": [
        "## Importamos las librerías a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rv0MvcgqDCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import Box2D\n",
        "from Box2D.b2 import (edgeShape, circleShape, fixtureDef, polygonShape, revoluteJointDef, contactListener)\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import colorize, seeding, EzPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z0s0ernqNL8",
        "colab_type": "text"
      },
      "source": [
        "## Constantes globales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLEcgKUjqM6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is simple 4-joints walker robot environment.\n",
        "#\n",
        "# There are two versions:\n",
        "#\n",
        "# - Normal, with slightly uneven terrain.\n",
        "#\n",
        "# - Hardcore with ladders, stumps, pitfalls.\n",
        "#\n",
        "# Reward is given for moving forward, total 300+ points up to the far end. If the robot falls,\n",
        "# it gets -100. Applying motor torque costs a small amount of points, more optimal agent\n",
        "# will get better score.\n",
        "#\n",
        "# Heuristic is provided for testing, it's also useful to get demonstrations to\n",
        "# learn from. To run heuristic:\n",
        "#\n",
        "# python gym/envs/box2d/bipedal_walker.py\n",
        "#\n",
        "# State consists of hull angle speed, angular velocity, horizontal speed, vertical speed,\n",
        "# position of joints and joints angular speed, legs contact with ground, and 10 lidar\n",
        "# rangefinder measurements to help to deal with the hardcore version. There's no coordinates\n",
        "# in the state vector. Lidar is less useful in normal version, but it works.\n",
        "#\n",
        "# To solve the game you need to get 300 points in 1600 time steps.\n",
        "#\n",
        "# To solve hardcore version you need 300 points in 2000 time steps.\n",
        "#\n",
        "# Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.\n",
        "\n",
        "FPS    = 50\n",
        "SCALE  = 30.0# escalamiento para dar formas \n",
        "# affects how fast-paced the game is, forces should be adjusted as well\n",
        "\n",
        "MOTORS_TORQUE = 80\n",
        "SPEED_HIP     = 4\n",
        "SPEED_KNEE    = 6\n",
        "LIDAR_RANGE   = 160/SCALE # rango de visión del laser\n",
        "\n",
        "INITIAL_RANDOM = 5\n",
        "\n",
        "HULL_POLY =[\n",
        "    (-30,+9), (+6,+9), (+34,+1),\n",
        "    (+34,-8), (-30,-8)\n",
        "    ]#puntos para generar el body\n",
        "LEG_DOWN = -8/SCALE\n",
        "LEG_W, LEG_H = 8/SCALE, 34/SCALE\n",
        "\n",
        "VIEWPORT_W = 600\n",
        "VIEWPORT_H = 400\n",
        "\n",
        "TERRAIN_STEP   = 14/SCALE \n",
        "TERRAIN_LENGTH = 200     # in steps\n",
        "TERRAIN_HEIGHT = VIEWPORT_H/SCALE/4\n",
        "TERRAIN_GRASS    = 10    # low long are grass spots, in steps\n",
        "TERRAIN_STARTPAD = 20    # in steps\n",
        "FRICTION = 2.5\n",
        "\n",
        "HULL_FD = fixtureDef(\n",
        "                shape=polygonShape(vertices=[ (x/SCALE,y/SCALE) for x,y in HULL_POLY ]),\n",
        "                density=5.0,\n",
        "                friction=0.1,\n",
        "                categoryBits=0x0020,\n",
        "                maskBits=0x001,  # collide only with ground\n",
        "                restitution=0.0) # 0.99 bouncy\n",
        "\n",
        "LEG_FD = fixtureDef(\n",
        "                    shape=polygonShape(box=(LEG_W/2, LEG_H/2)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001)\n",
        "\n",
        "LOWER_FD = fixtureDef(\n",
        "                    shape=polygonShape(box=(0.8*LEG_W/2, LEG_H/2)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsfzo4CEqQec",
        "colab_type": "text"
      },
      "source": [
        "## Entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKPc9xuql4q",
        "colab_type": "text"
      },
      "source": [
        "### ContactDetector (contactListener)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0m7Gr7qpZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContactDetector(contactListener):\n",
        "    def __init__(self, env):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "    def BeginContact(self, contact):\n",
        "        if self.env.hull==contact.fixtureA.body or self.env.hull==contact.fixtureB.body:\n",
        "            self.env.game_over = True\n",
        "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
        "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                leg.ground_contact = True\n",
        "    def EndContact(self, contact):\n",
        "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
        "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                leg.ground_contact = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cISQftcyqrpK",
        "colab_type": "text"
      },
      "source": [
        "### BipedalWalker (gym.Env, EzPickle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67eQNStqq3Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BipedalWalker(gym.Env, EzPickle):\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array'],\n",
        "        'video.frames_per_second' : FPS\n",
        "    }\n",
        "\n",
        "    hardcore = False\n",
        "\n",
        "    def __init__(self):\n",
        "        EzPickle.__init__(self)\n",
        "        self.seed()\n",
        "        self.viewer = None\n",
        "\n",
        "        self.world = Box2D.b2World()\n",
        "        self.terrain = None\n",
        "        self.hull = None\n",
        "\n",
        "        self.prev_shaping = None\n",
        "\n",
        "        self.fd_polygon = fixtureDef(\n",
        "                        shape = polygonShape(vertices=\n",
        "                        [(0, 0),\n",
        "                         (1, 0),\n",
        "                         (1, -1),\n",
        "                         (0, -1)]),\n",
        "                        friction = FRICTION)\n",
        "\n",
        "        self.fd_edge = fixtureDef(\n",
        "                    shape = edgeShape(vertices=\n",
        "                    [(0, 0),\n",
        "                     (1, 1)]),\n",
        "                    friction = FRICTION,\n",
        "                    categoryBits=0x0001,\n",
        "                )\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "        high = np.array([np.inf] * 24)\n",
        "        self.action_space = spaces.Box(np.array([-1, -1, -1, -1]), np.array([1, 1, 1, 1]), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def _destroy(self):\n",
        "        if not self.terrain: return\n",
        "        self.world.contactListener = None\n",
        "        for t in self.terrain:\n",
        "            self.world.DestroyBody(t)\n",
        "        self.terrain = []\n",
        "        self.world.DestroyBody(self.hull)\n",
        "        self.hull = None\n",
        "        for leg in self.legs:\n",
        "            self.world.DestroyBody(leg)\n",
        "        self.legs = []\n",
        "        self.joints = []\n",
        "\n",
        "    def _generate_terrain(self, hardcore):\n",
        "        GRASS, STUMP, STAIRS, PIT, _STATES_ = range(5)\n",
        "        state    = GRASS\n",
        "        velocity = 0.0\n",
        "        y        = TERRAIN_HEIGHT\n",
        "        counter  = TERRAIN_STARTPAD\n",
        "        oneshot  = False\n",
        "        self.terrain   = []\n",
        "        self.terrain_x = []\n",
        "        self.terrain_y = []\n",
        "        for i in range(TERRAIN_LENGTH):\n",
        "            x = i*TERRAIN_STEP\n",
        "            self.terrain_x.append(x)\n",
        "\n",
        "            if state==GRASS and not oneshot:\n",
        "                velocity = 0.8*velocity + 0.01*np.sign(TERRAIN_HEIGHT - y)\n",
        "                if i > TERRAIN_STARTPAD: velocity += self.np_random.uniform(-1, 1)/SCALE   #1\n",
        "                y += velocity\n",
        "\n",
        "            elif state==PIT and oneshot:\n",
        "                counter = self.np_random.randint(3, 5)\n",
        "                poly = [\n",
        "                    (x,              y),\n",
        "                    (x+TERRAIN_STEP, y),\n",
        "                    (x+TERRAIN_STEP, y-4*TERRAIN_STEP),\n",
        "                    (x,              y-4*TERRAIN_STEP),\n",
        "                    ]\n",
        "                self.fd_polygon.shape.vertices=poly\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "\n",
        "                self.fd_polygon.shape.vertices=[(p[0]+TERRAIN_STEP*counter,p[1]) for p in poly]\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "                counter += 2\n",
        "                original_y = y\n",
        "\n",
        "            elif state==PIT and not oneshot:\n",
        "                y = original_y\n",
        "                if counter > 1:\n",
        "                    y -= 4*TERRAIN_STEP\n",
        "\n",
        "            elif state==STUMP and oneshot:\n",
        "                counter = self.np_random.randint(1, 3)\n",
        "                poly = [\n",
        "                    (x,                      y),\n",
        "                    (x+counter*TERRAIN_STEP, y),\n",
        "                    (x+counter*TERRAIN_STEP, y+counter*TERRAIN_STEP),\n",
        "                    (x,                      y+counter*TERRAIN_STEP),\n",
        "                    ]\n",
        "                self.fd_polygon.shape.vertices=poly\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "\n",
        "            elif state==STAIRS and oneshot:\n",
        "                stair_height = +1 if self.np_random.rand() > 0.5 else -1\n",
        "                stair_width = self.np_random.randint(4, 5)\n",
        "                stair_steps = self.np_random.randint(3, 5)\n",
        "                original_y = y\n",
        "                for s in range(stair_steps):\n",
        "                    poly = [\n",
        "                        (x+(    s*stair_width)*TERRAIN_STEP, y+(   s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+((1+s)*stair_width)*TERRAIN_STEP, y+(   s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+((1+s)*stair_width)*TERRAIN_STEP, y+(-1+s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+(    s*stair_width)*TERRAIN_STEP, y+(-1+s*stair_height)*TERRAIN_STEP),\n",
        "                        ]\n",
        "                    self.fd_polygon.shape.vertices=poly\n",
        "                    t = self.world.CreateStaticBody(\n",
        "                        fixtures = self.fd_polygon)\n",
        "                    t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                    self.terrain.append(t)\n",
        "                counter = stair_steps*stair_width\n",
        "\n",
        "            elif state==STAIRS and not oneshot:\n",
        "                s = stair_steps*stair_width - counter - stair_height\n",
        "                n = s/stair_width\n",
        "                y = original_y + (n*stair_height)*TERRAIN_STEP\n",
        "\n",
        "            oneshot = False\n",
        "            self.terrain_y.append(y)\n",
        "            counter -= 1\n",
        "            if counter==0:\n",
        "                counter = self.np_random.randint(TERRAIN_GRASS/2, TERRAIN_GRASS)\n",
        "                if state==GRASS and hardcore:\n",
        "                    state = self.np_random.randint(1, _STATES_)\n",
        "                    oneshot = True\n",
        "                else:\n",
        "                    state = GRASS\n",
        "                    oneshot = True\n",
        "\n",
        "        self.terrain_poly = []\n",
        "        for i in range(TERRAIN_LENGTH-1):\n",
        "            poly = [\n",
        "                (self.terrain_x[i],   self.terrain_y[i]),\n",
        "                (self.terrain_x[i+1], self.terrain_y[i+1])\n",
        "                ]\n",
        "            self.fd_edge.shape.vertices=poly\n",
        "            t = self.world.CreateStaticBody(\n",
        "                fixtures = self.fd_edge)\n",
        "            color = (0.3, 1.0 if i%2==0 else 0.8, 0.3)\n",
        "            t.color1 = color\n",
        "            t.color2 = color\n",
        "            self.terrain.append(t)\n",
        "            color = (0.4, 0.6, 0.3)\n",
        "            poly += [ (poly[1][0], 0), (poly[0][0], 0) ]\n",
        "            self.terrain_poly.append( (poly, color) )\n",
        "        self.terrain.reverse()\n",
        "\n",
        "    def _generate_clouds(self):\n",
        "        # Sorry for the clouds, couldn't resist\n",
        "        self.cloud_poly   = []\n",
        "        for i in range(TERRAIN_LENGTH//20):\n",
        "            x = self.np_random.uniform(0, TERRAIN_LENGTH)*TERRAIN_STEP\n",
        "            y = VIEWPORT_H/SCALE*3/4\n",
        "            poly = [\n",
        "                (x+15*TERRAIN_STEP*math.sin(3.14*2*a/5)+self.np_random.uniform(0,5*TERRAIN_STEP),\n",
        "                 y+ 5*TERRAIN_STEP*math.cos(3.14*2*a/5)+self.np_random.uniform(0,5*TERRAIN_STEP) )\n",
        "                for a in range(5) ]\n",
        "            x1 = min( [p[0] for p in poly] )\n",
        "            x2 = max( [p[0] for p in poly] )\n",
        "            self.cloud_poly.append( (poly,x1,x2) )\n",
        "\n",
        "    def reset(self):\n",
        "        self._destroy()\n",
        "        self.world.contactListener_bug_workaround = ContactDetector(self)\n",
        "        self.world.contactListener = self.world.contactListener_bug_workaround\n",
        "        self.game_over = False\n",
        "        self.prev_shaping = None\n",
        "        self.scroll = 0.0\n",
        "        self.lidar_render = 0\n",
        "\n",
        "        W = VIEWPORT_W/SCALE\n",
        "        H = VIEWPORT_H/SCALE\n",
        "\n",
        "        self._generate_terrain(self.hardcore)\n",
        "        self._generate_clouds()\n",
        "\n",
        "        init_x = TERRAIN_STEP*TERRAIN_STARTPAD/2\n",
        "        init_y = TERRAIN_HEIGHT+2*LEG_H\n",
        "        self.hull = self.world.CreateDynamicBody(\n",
        "            position = (init_x, init_y),\n",
        "            fixtures = HULL_FD\n",
        "                )\n",
        "        self.hull.color1 = (0.5,0.4,0.9)\n",
        "        self.hull.color2 = (0.3,0.3,0.5)\n",
        "        self.hull.ApplyForceToCenter((self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM), 0), True)\n",
        "\n",
        "        self.legs = []\n",
        "        self.joints = []\n",
        "        for i in [-1,+1]:\n",
        "            leg = self.world.CreateDynamicBody(\n",
        "                position = (init_x, init_y - LEG_H/2 - LEG_DOWN),\n",
        "                angle = (i*0.05),\n",
        "                fixtures = LEG_FD\n",
        "                )\n",
        "            leg.color1 = (0.6-i/10., 0.3-i/10., 0.5-i/10.)\n",
        "            leg.color2 = (0.4-i/10., 0.2-i/10., 0.3-i/10.)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=self.hull,\n",
        "                bodyB=leg,\n",
        "                localAnchorA=(0, LEG_DOWN),\n",
        "                localAnchorB=(0, LEG_H/2),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=MOTORS_TORQUE,\n",
        "                motorSpeed = i,\n",
        "                lowerAngle = -0.8,\n",
        "                upperAngle = 1.1,\n",
        "                )\n",
        "            self.legs.append(leg)\n",
        "            self.joints.append(self.world.CreateJoint(rjd))\n",
        "\n",
        "            lower = self.world.CreateDynamicBody(\n",
        "                position = (init_x, init_y - LEG_H*3/2 - LEG_DOWN),\n",
        "                angle = (i*0.05),\n",
        "                fixtures = LOWER_FD\n",
        "                )\n",
        "            lower.color1 = (0.6-i/10., 0.3-i/10., 0.5-i/10.)\n",
        "            lower.color2 = (0.4-i/10., 0.2-i/10., 0.3-i/10.)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=leg,\n",
        "                bodyB=lower,\n",
        "                localAnchorA=(0, -LEG_H/2),\n",
        "                localAnchorB=(0, LEG_H/2),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=MOTORS_TORQUE,\n",
        "                motorSpeed = 1,\n",
        "                lowerAngle = -1.6,\n",
        "                upperAngle = -0.1,\n",
        "                )\n",
        "            lower.ground_contact = False\n",
        "            self.legs.append(lower)\n",
        "            self.joints.append(self.world.CreateJoint(rjd))\n",
        "\n",
        "        self.drawlist = self.terrain + self.legs + [self.hull]\n",
        "\n",
        "        class LidarCallback(Box2D.b2.rayCastCallback):\n",
        "            def ReportFixture(self, fixture, point, normal, fraction):\n",
        "                if (fixture.filterData.categoryBits & 1) == 0:\n",
        "                    return 1\n",
        "                self.p2 = point\n",
        "                self.fraction = fraction\n",
        "                return 0\n",
        "        self.lidar = [LidarCallback() for _ in range(10)]\n",
        "\n",
        "        return self.step(np.array([0,0,0,0]))[0]\n",
        "\n",
        "    def step(self, action):\n",
        "        #self.hull.ApplyForceToCenter((0, 20), True) -- Uncomment this to receive a bit of stability help\n",
        "        control_speed = False  # Should be easier as well\n",
        "        if control_speed:\n",
        "            self.joints[0].motorSpeed = float(SPEED_HIP  * np.clip(action[0], -1, 1))\n",
        "            self.joints[1].motorSpeed = float(SPEED_KNEE * np.clip(action[1], -1, 1))\n",
        "            self.joints[2].motorSpeed = float(SPEED_HIP  * np.clip(action[2], -1, 1))\n",
        "            self.joints[3].motorSpeed = float(SPEED_KNEE * np.clip(action[3], -1, 1))\n",
        "        else:\n",
        "            self.joints[0].motorSpeed     = float(SPEED_HIP     * np.sign(action[0]))\n",
        "            self.joints[0].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[0]), 0, 1))\n",
        "            self.joints[1].motorSpeed     = float(SPEED_KNEE    * np.sign(action[1]))\n",
        "            self.joints[1].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[1]), 0, 1))\n",
        "            self.joints[2].motorSpeed     = float(SPEED_HIP     * np.sign(action[2]))\n",
        "            self.joints[2].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[2]), 0, 1))\n",
        "            self.joints[3].motorSpeed     = float(SPEED_KNEE    * np.sign(action[3]))\n",
        "            self.joints[3].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[3]), 0, 1))\n",
        "\n",
        "        self.world.Step(1.0/FPS, 6*30, 2*30)\n",
        "\n",
        "        pos = self.hull.position\n",
        "        vel = self.hull.linearVelocity\n",
        "\n",
        "        for i in range(10):\n",
        "            self.lidar[i].fraction = 1.0\n",
        "            self.lidar[i].p1 = pos\n",
        "            self.lidar[i].p2 = (\n",
        "                pos[0] + math.sin(1.5*i/10.0)*LIDAR_RANGE,\n",
        "                pos[1] - math.cos(1.5*i/10.0)*LIDAR_RANGE)\n",
        "            self.world.RayCast(self.lidar[i], self.lidar[i].p1, self.lidar[i].p2)\n",
        "\n",
        "        state = [\n",
        "            self.hull.angle,        # Normal angles up to 0.5 here, but sure more is possible.\n",
        "            2.0*self.hull.angularVelocity/FPS,\n",
        "            0.3*vel.x*(VIEWPORT_W/SCALE)/FPS,  # Normalized to get -1..1 range\n",
        "            0.3*vel.y*(VIEWPORT_H/SCALE)/FPS,\n",
        "            self.joints[0].angle,   # This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)\n",
        "            self.joints[0].speed / SPEED_HIP,\n",
        "            self.joints[1].angle + 1.0,\n",
        "            self.joints[1].speed / SPEED_KNEE,\n",
        "            1.0 if self.legs[1].ground_contact else 0.0,\n",
        "            self.joints[2].angle,\n",
        "            self.joints[2].speed / SPEED_HIP,\n",
        "            self.joints[3].angle + 1.0,\n",
        "            self.joints[3].speed / SPEED_KNEE,\n",
        "            1.0 if self.legs[3].ground_contact else 0.0\n",
        "            ]\n",
        "        state += [l.fraction for l in self.lidar]\n",
        "        assert len(state)==24\n",
        "\n",
        "        self.scroll = pos.x - VIEWPORT_W/SCALE/5\n",
        "\n",
        "        shaping  = 130*pos[0]/SCALE   # moving forward is a way to receive reward (normalized to get 300 on completion)\n",
        "        shaping -= 5.0*abs(state[0])  # keep head straight, other than that and falling, any behavior is unpunished\n",
        "\n",
        "        reward = 0\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        for a in action:\n",
        "            reward -= 0.00035 * MOTORS_TORQUE * np.clip(np.abs(a), 0, 1)\n",
        "            # normalized to about -50.0 using heuristic, more optimal agent should spend less\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or pos[0] < 0:\n",
        "            reward = -100\n",
        "            done   = True\n",
        "        if pos[0] > (TERRAIN_LENGTH-TERRAIN_GRASS)*TERRAIN_STEP:\n",
        "            done   = True\n",
        "        return np.array(state), reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        from gym.envs.classic_control import rendering\n",
        "        if self.viewer is None:\n",
        "            self.viewer = rendering.Viewer(VIEWPORT_W, VIEWPORT_H)\n",
        "        self.viewer.set_bounds(self.scroll, VIEWPORT_W/SCALE + self.scroll, 0, VIEWPORT_H/SCALE)\n",
        "\n",
        "        self.viewer.draw_polygon( [\n",
        "            (self.scroll,                  0),\n",
        "            (self.scroll+VIEWPORT_W/SCALE, 0),\n",
        "            (self.scroll+VIEWPORT_W/SCALE, VIEWPORT_H/SCALE),\n",
        "            (self.scroll,                  VIEWPORT_H/SCALE),\n",
        "            ], color=(0.9, 0.9, 1.0) )\n",
        "        for poly,x1,x2 in self.cloud_poly:\n",
        "            if x2 < self.scroll/2: continue\n",
        "            if x1 > self.scroll/2 + VIEWPORT_W/SCALE: continue\n",
        "            self.viewer.draw_polygon( [(p[0]+self.scroll/2, p[1]) for p in poly], color=(1,1,1))\n",
        "        for poly, color in self.terrain_poly:\n",
        "            if poly[1][0] < self.scroll: continue\n",
        "            if poly[0][0] > self.scroll + VIEWPORT_W/SCALE: continue\n",
        "            self.viewer.draw_polygon(poly, color=color)\n",
        "\n",
        "        self.lidar_render = (self.lidar_render+1) % 100\n",
        "        i = self.lidar_render\n",
        "        if i < 2*len(self.lidar):\n",
        "            l = self.lidar[i] if i < len(self.lidar) else self.lidar[len(self.lidar)-i-1]\n",
        "            self.viewer.draw_polyline( [l.p1, l.p2], color=(1,0,0), linewidth=1 )\n",
        "\n",
        "        for obj in self.drawlist:\n",
        "            for f in obj.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    t = rendering.Transform(translation=trans*f.shape.pos)\n",
        "                    self.viewer.draw_circle(f.shape.radius, 30, color=obj.color1).add_attr(t)\n",
        "                    self.viewer.draw_circle(f.shape.radius, 30, color=obj.color2, filled=False, linewidth=2).add_attr(t)\n",
        "                else:\n",
        "                    path = [trans*v for v in f.shape.vertices]\n",
        "                    self.viewer.draw_polygon(path, color=obj.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj.color2, linewidth=2)\n",
        "\n",
        "        flagy1 = TERRAIN_HEIGHT\n",
        "        flagy2 = flagy1 + 50/SCALE\n",
        "        x = TERRAIN_STEP*3\n",
        "        self.viewer.draw_polyline( [(x, flagy1), (x, flagy2)], color=(0,0,0), linewidth=2 )\n",
        "        f = [(x, flagy2), (x, flagy2-10/SCALE), (x+25/SCALE, flagy2-5/SCALE)]\n",
        "        self.viewer.draw_polygon(f, color=(0.9,0.2,0) )\n",
        "        self.viewer.draw_polyline(f + [f[0]], color=(0,0,0), linewidth=2 )\n",
        "\n",
        "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "            self.viewer = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJKGn0VAq7QK",
        "colab_type": "text"
      },
      "source": [
        "### Clase BipedalWalkerHardcore(BipedalWalker)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX6rnTXdq6y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BipedalWalkerHardcore(BipedalWalker):\n",
        "    hardcore = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Xp71dWq_9L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# heuristic()\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqezS0Aloblq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if __name__==\"__main__\":\n",
        "\n",
        "def heuristic(file_name=\"video\"):  \n",
        "  \n",
        "  # Heurisic: suboptimal, have no notion of balance.\n",
        "  env = BipedalWalkerHardcore() #Aquí se elige que entorno será\n",
        "  env.reset()\n",
        "\n",
        "  ###################################################\n",
        "  video=[]\n",
        "  prev_screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(prev_screen)\n",
        "  image=0\n",
        "  ###################################################\n",
        "  \n",
        "  steps = 0\n",
        "  total_reward = 0\n",
        "  a = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "  STAY_ON_ONE_LEG, PUT_OTHER_DOWN, PUSH_OFF = 1,2,3\n",
        "  SPEED = 0.29  # Will fall forward on higher speed\n",
        "  state = STAY_ON_ONE_LEG\n",
        "  moving_leg = 0\n",
        "  supporting_leg = 1 - moving_leg\n",
        "  SUPPORT_KNEE_ANGLE = +0.1\n",
        "  supporting_knee_angle = SUPPORT_KNEE_ANGLE\n",
        "  \n",
        "  while True: \n",
        "    ###################################################\n",
        "    image += 1\n",
        "    ###################################################\n",
        "    s, r, done, info = env.step(a)\n",
        "\n",
        "    total_reward += r\n",
        "    #if steps % 20 == 0 or done:\n",
        "    #    print(\"\\naction \" + str([\"{:+0.2f}\".format(x) for x in a]))\n",
        "    #    print(\"step {} total_reward {:+0.2f}\".format(steps, total_reward))\n",
        "    #    print(\"hull \" + str([\"{:+0.2f}\".format(x) for x in s[0:4] ]))\n",
        "    #    print(\"leg0 \" + str([\"{:+0.2f}\".format(x) for x in s[4:9] ]))\n",
        "    #    print(\"leg1 \" + str([\"{:+0.2f}\".format(x) for x in s[9:14]]))\n",
        "    steps += 1\n",
        "\n",
        "    contact0 = s[8]\n",
        "    contact1 = s[13]\n",
        "    moving_s_base = 4 + 5*moving_leg\n",
        "    supporting_s_base = 4 + 5*supporting_leg\n",
        "\n",
        "    hip_targ  = [None,None]   # -0.8 .. +1.1\n",
        "    knee_targ = [None,None]   # -0.6 .. +0.9\n",
        "    hip_todo  = [0.0, 0.0]\n",
        "    knee_todo = [0.0, 0.0]\n",
        "\n",
        "    if state==STAY_ON_ONE_LEG:\n",
        "        hip_targ[moving_leg]  = 1.1\n",
        "        knee_targ[moving_leg] = -0.6\n",
        "        supporting_knee_angle += 0.03\n",
        "        if s[2] > SPEED: supporting_knee_angle += 0.03\n",
        "        supporting_knee_angle = min( supporting_knee_angle, SUPPORT_KNEE_ANGLE )\n",
        "        knee_targ[supporting_leg] = supporting_knee_angle\n",
        "        if s[supporting_s_base+0] < 0.10: # supporting leg is behind\n",
        "            state = PUT_OTHER_DOWN\n",
        "    if state==PUT_OTHER_DOWN:\n",
        "        hip_targ[moving_leg]  = +0.1\n",
        "        knee_targ[moving_leg] = SUPPORT_KNEE_ANGLE\n",
        "        knee_targ[supporting_leg] = supporting_knee_angle\n",
        "        if s[moving_s_base+4]:\n",
        "            state = PUSH_OFF\n",
        "            supporting_knee_angle = min( s[moving_s_base+2], SUPPORT_KNEE_ANGLE )\n",
        "    if state==PUSH_OFF:\n",
        "        knee_targ[moving_leg] = supporting_knee_angle\n",
        "        knee_targ[supporting_leg] = +1.0\n",
        "        if s[supporting_s_base+2] > 0.88 or s[2] > 1.2*SPEED:\n",
        "            state = STAY_ON_ONE_LEG\n",
        "            moving_leg = 1 - moving_leg\n",
        "            supporting_leg = 1 - moving_leg\n",
        "\n",
        "    if hip_targ[0]: hip_todo[0] = 0.9*(hip_targ[0] - s[4]) - 0.25*s[5]\n",
        "    if hip_targ[1]: hip_todo[1] = 0.9*(hip_targ[1] - s[9]) - 0.25*s[10]\n",
        "    if knee_targ[0]: knee_todo[0] = 4.0*(knee_targ[0] - s[6])  - 0.25*s[7]\n",
        "    if knee_targ[1]: knee_todo[1] = 4.0*(knee_targ[1] - s[11]) - 0.25*s[12]\n",
        "\n",
        "    hip_todo[0] -= 0.9*(0-s[0]) - 1.5*s[1] # PID to keep head strait\n",
        "    hip_todo[1] -= 0.9*(0-s[0]) - 1.5*s[1]\n",
        "    knee_todo[0] -= 15.0*s[3]  # vertical speed, to damp oscillations\n",
        "    knee_todo[1] -= 15.0*s[3]\n",
        "\n",
        "    a[0] = hip_todo[0]\n",
        "    a[1] = knee_todo[0]\n",
        "    a[2] = hip_todo[1]\n",
        "    a[3] = knee_todo[1]\n",
        "    a = np.clip(0.5*a, -1.0, 1.0)\n",
        "\n",
        "\n",
        "    ###################################################\n",
        "    if image%5==0: #Cada cuántas acciones renderizamos\n",
        "      screen = env.render(mode='rgb_array')\n",
        "      video.append(screen)\n",
        "      #plt.imshow(screen)\n",
        "      #ipythondisplay.clear_output(wait=True)\n",
        "      #ipythondisplay.display(plt.gcf())\n",
        "    ###################################################\n",
        "\n",
        "    if done: \n",
        "      video.append(screen) \n",
        "      break\n",
        "  #ipythondisplay.clear_output(wait=True)\n",
        "  env.close()\n",
        "  generate_video(video,file_name)\n",
        "  print(\"Video generado, se muestra el frame final\")\n",
        "  deleter(len(video))\n",
        "  try:\n",
        "    files.download(\"/content/\"+file_name+\".mp4\")\n",
        "  except:\n",
        "    print(\"No se pudo descargar correctamente, hágalo manual\")\n",
        "    pass\n",
        "  print(\"Descargando...\")\n",
        "  return (\"Heuristic finalizado\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vas1vRUt62Wg",
        "colab_type": "text"
      },
      "source": [
        "### Generar video en real time (No recomendado)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv-tYTCc6Gwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(video)):\n",
        "#  plt.imshow(video[i])  \n",
        "#  ipythondisplay.display(plt.gcf())\n",
        "#  ipythondisplay.clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI1j_cjAW01u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ddpg()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://github.com/vy007vikas/PyTorch-ActorCriticRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfY-ALUOXTJO",
        "colab_type": "text"
      },
      "source": [
        "## Instalando PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dPJZNHnW5ID",
        "colab_type": "code",
        "outputId": "0dcb1ca5-3a35-49f3-fb10-a7bc6f179526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5bGYQEPXWqe",
        "colab_type": "text"
      },
      "source": [
        "## Habilitando uso de GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU5TA8NzXeqY",
        "colab_type": "text"
      },
      "source": [
        "Idea from https://colab.research.google.com/drive/1jxUPzMsAkBboHMQtGyfv5M5c7hU8Ss2c#scrollTo=oQ6isf-kI2HD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvKWUhkdSTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ORIGINAL ESCRITO EN .PY\n",
        "#MAIN.PY\n",
        "from __future__ import division\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "#import train\n",
        "#import buffer\n",
        "\n",
        "#BUFFER.PY\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "#MODEL.PY\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "#TRAIN.PY\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#import utils\n",
        "#import model\n",
        "\n",
        "\n",
        "#IMPORT UTILS\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import shutil\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLud7fmH2pdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "# torch_float = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3_1mBxQUhi",
        "colab_type": "text"
      },
      "source": [
        "## BUFFER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilYvZFyeWjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BUFFER\n",
        "class MemoryBuffer:\n",
        "\n",
        "\tdef __init__(self, size):\n",
        "\t\tself.buffer = deque(maxlen=size)\n",
        "\t\tself.maxSize = size\n",
        "\t\tself.len = 0\n",
        "\n",
        "\tdef sample(self, count):\n",
        "\t\t\"\"\"\n",
        "\t\tsamples a random batch from the replay memory buffer\n",
        "\t\t:param count: batch size\n",
        "\t\t:return: batch (numpy array)\n",
        "\t\t\"\"\"\n",
        "\t\tbatch = []\n",
        "\t\tcount = min(count, self.len)\n",
        "\t\tbatch = random.sample(self.buffer, count)\n",
        "\n",
        "\t\ts_arr = np.float32([arr[0] for arr in batch])\n",
        "\t\ta_arr = np.float32([arr[1] for arr in batch])\n",
        "\t\tr_arr = np.float32([arr[2] for arr in batch])\n",
        "\t\ts1_arr = np.float32([arr[3] for arr in batch])\n",
        "\n",
        "\t\treturn s_arr, a_arr, r_arr, s1_arr\n",
        "\n",
        "\tdef len(self):\n",
        "\t\treturn self.len\n",
        "\n",
        "\tdef add(self, s, a, r, s1):\n",
        "\t\t\"\"\"\n",
        "\t\tadds a particular transaction in the memory buffer\n",
        "\t\t:param s: current state\n",
        "\t\t:param a: action taken\n",
        "\t\t:param r: reward received\n",
        "\t\t:param s1: next state\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\ttransition = (s,a,r,s1)\n",
        "\t\tself.len += 1\n",
        "\t\tif self.len > self.maxSize:\n",
        "\t\t\tself.len = self.maxSize\n",
        "\t\tself.buffer.append(transition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McIsP5dAQWK2",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85vC4VM-eiGs",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "# MODEL\n",
        "EPS = 0.003\n",
        "\n",
        "def fanin_init(size, fanin=None):\n",
        "\tfanin = fanin or size[0]\n",
        "\tv = 1. / np.sqrt(fanin)\n",
        "\treturn torch.Tensor(size).uniform_(-v, v)\n",
        "\n",
        "class Critic(nn.Module):\n",
        "\n",
        "\tdef __init__(self, state_dim, action_dim):\n",
        "\t\t\"\"\"\n",
        "\t\t:param state_dim: Dimension of input state (int)\n",
        "\t\t:param action_dim: Dimension of input action (int)\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Critic, self).__init__()\n",
        "\n",
        "\t\tself.state_dim = state_dim\n",
        "\t\tself.action_dim = action_dim\n",
        "\n",
        "\t\tself.fcs1 = nn.Linear(state_dim,256)\n",
        "\t\tself.fcs1.weight.data = fanin_init(self.fcs1.weight.data.size())\n",
        "\t\tself.fcs2 = nn.Linear(256,128)\n",
        "\t\tself.fcs2.weight.data = fanin_init(self.fcs2.weight.data.size())\n",
        "\n",
        "\t\tself.fca1 = nn.Linear(action_dim,128)\n",
        "\t\tself.fca1.weight.data = fanin_init(self.fca1.weight.data.size())\n",
        "\n",
        "\t\tself.fc2 = nn.Linear(256,128)\n",
        "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
        "\n",
        "\t\tself.fc3 = nn.Linear(128,1)\n",
        "\t\tself.fc3.weight.data.uniform_(-EPS,EPS)\n",
        "\n",
        "\tdef forward(self, state, action):\n",
        "\t\t\"\"\"\n",
        "\t\treturns Value function Q(s,a) obtained from critic network\n",
        "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
        "\t\t:param action: Input Action (Torch Variable : [n,action_dim] )\n",
        "\t\t:return: Value function : Q(S,a) (Torch Variable : [n,1] )\n",
        "\t\t\"\"\"\n",
        "\t\ts1 = F.relu(self.fcs1(state))\n",
        "\t\ts2 = F.relu(self.fcs2(s1))\n",
        "\t\ta1 = F.relu(self.fca1(action))\n",
        "\t\tx = torch.cat((s2,a1),dim=1)\n",
        "\n",
        "\t\tx = F.relu(self.fc2(x))\n",
        "\t\tx = self.fc3(x)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Actor(nn.Module):\n",
        "\n",
        "\tdef __init__(self, state_dim, action_dim, action_lim):\n",
        "\t\t\"\"\"\n",
        "\t\t:param state_dim: Dimension of input state (int)\n",
        "\t\t:param action_dim: Dimension of output action (int)\n",
        "\t\t:param action_lim: Used to limit action in [-action_lim,action_lim]\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Actor, self).__init__()\n",
        "\n",
        "\t\tself.state_dim = state_dim\n",
        "\t\tself.action_dim = action_dim\n",
        "\t\tself.action_lim = action_lim\n",
        "\n",
        "\t\tself.fc1 = nn.Linear(state_dim,256)\n",
        "\t\tself.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
        "\n",
        "\t\tself.fc2 = nn.Linear(256,128)\n",
        "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
        "\n",
        "\t\tself.fc3 = nn.Linear(128,64)\n",
        "\t\tself.fc3.weight.data = fanin_init(self.fc3.weight.data.size())\n",
        "\n",
        "\t\tself.fc4 = nn.Linear(64,action_dim)\n",
        "\t\tself.fc4.weight.data.uniform_(-EPS,EPS)\n",
        "\n",
        "\tdef forward(self, state):\n",
        "\t\t\"\"\"\n",
        "\t\treturns policy function Pi(s) obtained from actor network\n",
        "\t\tthis function is a gaussian prob distribution for all actions\n",
        "\t\twith mean lying in (-1,1) and sigma lying in (0,1)\n",
        "\t\tThe sampled action can , then later be rescaled\n",
        "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
        "\t\t:return: Output action (Torch Variable: [n,action_dim] )\n",
        "\t\t\"\"\"\n",
        "\t\tx = torch.relu(self.fc1(state))\n",
        "\t\tx = torch.relu(self.fc2(x))\n",
        "\t\tx = torch.relu(self.fc3(x))\n",
        "\t\taction = torch.tanh(self.fc4(x))\n",
        "\n",
        "\t\taction = action * self.action_lim\n",
        "\n",
        "\t\treturn action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBYKy2ZIQXo6",
        "colab_type": "text"
      },
      "source": [
        "## TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eRqqAH0elgE",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# TRAINER\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "GAMMA = 0.99\n",
        "TAU = 0.001\n",
        "class Trainer():\n",
        "  \n",
        "  def __init__(self, state_dim, action_dim, action_lim, ram):\n",
        "    #\"\"\"\n",
        "    #param state_dim: Dimensions of state (int)\n",
        "    #param action_dim: Dimension of action (int)\n",
        "    #param action_lim: Used to limit action in [-action_lim,action_lim]\n",
        "    #param ram: replay memory buffer object\n",
        "    #return\n",
        "    #\"\"\"\n",
        "    self.state_dim = state_dim\n",
        "    self.action_dim = action_dim\n",
        "    self.action_lim = action_lim\n",
        "    self.ram = ram\n",
        "    self.iter = 0\n",
        "    #self.noise = utils.OrnsteinUhlenbeckActionNoise(self.action_dim)\n",
        "    self.noise = OrnsteinUhlenbeckActionNoise(self.action_dim)    \n",
        "\n",
        "    #self.actor = model.Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.actor = Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    #self.target_actor = model.Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.target_actor = Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),LEARNING_RATE)\n",
        "\n",
        "    #self.critic = model.Critic(self.state_dim, self.action_dim)\n",
        "    self.critic = Critic(self.state_dim, self.action_dim)\n",
        "    #self.target_critic = model.Critic(self.state_dim, self.action_dim)\n",
        "    self.target_critic = Critic(self.state_dim, self.action_dim)\n",
        "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),LEARNING_RATE)\n",
        "\n",
        "    #utils.hard_update(self.target_actor, self.actor)\n",
        "    hard_update(self.target_actor, self.actor)\n",
        "    #utils.hard_update(self.target_critic, self.critic)\n",
        "    hard_update(self.target_critic, self.critic)\n",
        "  def get_exploitation_action(self,state):\n",
        "    #\"\"\"\n",
        "    #gets the action from target actor added with exploration noise\n",
        "    #:param state: state (Numpy array)\n",
        "    #:return: sampled action (Numpy array)\n",
        "    #\"\"\"\n",
        "    state = Variable(torch.from_numpy(state))\n",
        "    action = self.target_actor.forward(state).detach()\n",
        "    return action.data.numpy()\n",
        "  def get_exploration_action(self,state):\n",
        "    #\"\"\"\n",
        "    #gets the action from actor added with exploration noise\n",
        "    #:param state: state (Numpy array)\n",
        "    #:return: sampled action (Numpy array)\n",
        "    #\"\"\"\n",
        "    state = Variable(torch.from_numpy(state))\n",
        "    action = self.actor.forward(state).detach()\n",
        "    new_action = action.data.numpy() + (self.noise.sample() * self.action_lim)\n",
        "    return new_action\n",
        "  def optimize(self):\n",
        "    #\"\"\"\n",
        "    #Samples a random batch from replay memory and performs optimization\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    s1,a1,r1,s2 = self.ram.sample(BATCH_SIZE)\n",
        "\n",
        "    s1 = Variable(torch.from_numpy(s1))\n",
        "    a1 = Variable(torch.from_numpy(a1))\n",
        "    r1 = Variable(torch.from_numpy(r1))\n",
        "    s2 = Variable(torch.from_numpy(s2))\n",
        "\n",
        "    # ---------------------- optimize critic ----------------------\n",
        "    # Use target actor exploitation policy here for loss evaluation\n",
        "    a2 = self.target_actor.forward(s2).detach()\n",
        "    next_val = torch.squeeze(self.target_critic.forward(s2, a2).detach())\n",
        "    # y_exp = r + gamma*Q'( s2, pi'(s2))\n",
        "    y_expected = r1 + GAMMA*next_val\n",
        "    # y_pred = Q( s1, a1)\n",
        "    y_predicted = torch.squeeze(self.critic.forward(s1, a1))\n",
        "    # compute critic loss, and update the critic\n",
        "    loss_critic = F.smooth_l1_loss(y_predicted, y_expected)\n",
        "    self.critic_optimizer.zero_grad()\n",
        "    loss_critic.backward()\n",
        "    self.critic_optimizer.step()\n",
        "\n",
        "    # ---------------------- optimize actor ----------------------\n",
        "    pred_a1 = self.actor.forward(s1)\n",
        "    loss_actor = -1*torch.sum(self.critic.forward(s1, pred_a1))\n",
        "    self.actor_optimizer.zero_grad()\n",
        "    loss_actor.backward()\n",
        "    self.actor_optimizer.step()\n",
        "\n",
        "    #utils.soft_update(self.target_actor, self.actor, TAU)\n",
        "    soft_update(self.target_actor, self.actor, TAU)\n",
        "    #utils.soft_update(self.target_critic, self.critic, TAU)\n",
        "    soft_update(self.target_critic, self.critic, TAU)\n",
        "\n",
        "    # if self.iter % 100 == 0:\n",
        "    # \tprint 'Iteration :- ', self.iter, ' Loss_actor :- ', loss_actor.data.numpy(),\\\n",
        "    # \t\t' Loss_critic :- ', loss_critic.data.numpy()\n",
        "    # self.iter += 1\n",
        "  def save_models(self, episode_count):\n",
        "    #\"\"\"\n",
        "    #saves the target actor and critic models\n",
        "    #:param episode_count: the count of episodes iterated\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    torch.save(self.target_actor.state_dict(), '/content/' + str(episode_count) + '_actor.pt')\n",
        "    # Cambiamos dónde se guarda a content, anteriormente en Models\n",
        "    torch.save(self.target_critic.state_dict(), '/content/' + str(episode_count) + '_critic.pt')\n",
        "    print ('save_models: Models saved successfully')\n",
        "\n",
        "  def load_models(self, episode):\n",
        "    #\"\"\"\n",
        "    #loads the target actor and critic models, and copies them onto actor and critic models\n",
        "    #:param episode: the count of episodes iterated (used to find the file name)\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    self.actor.load_state_dict(torch.load('/content/' + str(episode) + '_actor.pt'))\n",
        "    self.critic.load_state_dict(torch.load('/content/' + str(episode) + '_critic.pt'))\n",
        "    #utils.hard_update(self.target_actor, self.actor)\n",
        "    hard_update(self.target_actor, self.actor)\n",
        "    #utils.hard_update(self.target_critic, self.critic)\n",
        "    hard_update(self.target_critic, self.critic)\n",
        "    print ('load_models: Models loaded succesfully')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-gILeJFQY2y",
        "colab_type": "text"
      },
      "source": [
        "## UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ewoApuepU0",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "8bbde63d-dd24-4507-d772-f78d5c944b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "#@title\n",
        "# UTILS\n",
        "def soft_update(target, source, tau):\n",
        "\t\"\"\"\n",
        "\tCopies the parameters from source network (x) to target network (y) using the below update\n",
        "\ty = TAU*x + (1 - TAU)*y\n",
        "\t:param target: Target network (PyTorch)\n",
        "\t:param source: Source network (PyTorch)\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
        "\t\ttarget_param.data.copy_(\n",
        "\t\t\ttarget_param.data * (1.0 - tau) + param.data * tau\n",
        "\t\t)\n",
        "\n",
        "\n",
        "def hard_update(target, source):\n",
        "\t\"\"\"\n",
        "\tCopies the parameters from source network to target network\n",
        "\t:param target: Target network (PyTorch)\n",
        "\t:param source: Source network (PyTorch)\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
        "\t\t\ttarget_param.data.copy_(param.data)\n",
        "\n",
        "\n",
        "def save_training_checkpoint(state, is_best, episode_count):\n",
        "\t\"\"\"\n",
        "\tSaves the models, with all training parameters intact\n",
        "\t:param state:\n",
        "\t:param is_best:\n",
        "\t:param filename:\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfilename = str(episode_count) + 'checkpoint.path.rar'\n",
        "\ttorch.save(state, filename)\n",
        "\tif is_best:\n",
        "\t\tshutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
        "class OrnsteinUhlenbeckActionNoise:\n",
        "\n",
        "\tdef __init__(self, action_dim, mu = 0, theta = 0.15, sigma = 0.2):\n",
        "\t\tself.action_dim = action_dim\n",
        "\t\tself.mu = mu\n",
        "\t\tself.theta = theta\n",
        "\t\tself.sigma = sigma\n",
        "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
        "\n",
        "\tdef sample(self):\n",
        "\t\tdx = self.theta * (self.mu - self.X)\n",
        "\t\tdx = dx + self.sigma * np.random.randn(len(self.X))\n",
        "\t\tself.X = self.X + dx\n",
        "\t\treturn self.X\n",
        "\n",
        "\n",
        "# use this to plot Ornstein Uhlenbeck random motion\n",
        "if __name__ == '__main__':\n",
        "\tou = OrnsteinUhlenbeckActionNoise(1)\n",
        "\tstates = []\n",
        "\tfor i in range(1000):\n",
        "\t\tstates.append(ou.sample())\n",
        "\timport matplotlib.pyplot as plt\n",
        "\n",
        "\tplt.plot(states)\n",
        "\tplt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGLQh/j8va2QKEHZMkQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klzEjv3lQaii",
        "colab_type": "text"
      },
      "source": [
        "## MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "code",
        "id": "tROD7XxO-KUj",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# MAIN\n",
        "##############################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from IPython.display import clear_output\n",
        "##############################################\n",
        "def ddpg(file_name=\"video\"):\n",
        "  env = BipedalWalkerHardcore() #Aquí se elige que entorno será\n",
        "  env.reset()\n",
        "  ################################\n",
        "#   quiero_n_videos=10\n",
        "  ###############################\n",
        "  MAX_EPISODES = 500\n",
        "  MAX_STEPS = 1000\n",
        "  MAX_BUFFER = 1000000\n",
        "  MAX_TOTAL_REWARD = 300\n",
        "  S_DIM = env.observation_space.shape[0]\n",
        "  A_DIM = env.action_space.shape[0]\n",
        "  A_MAX = env.action_space.high[0]\n",
        "\n",
        "  print(\" State Dimensions :- \", S_DIM)\n",
        "  print(\" Action Dimensions :- \", A_DIM)\n",
        "  print(\" Action Max :- \", A_MAX)\n",
        "\n",
        "  \n",
        "  \n",
        "  #ram = buffer.MemoryBuffer(MAX_BUFFER)\n",
        "  ram = MemoryBuffer(MAX_BUFFER)\n",
        "  #trainer = train.Trainer(S_DIM, A_DIM, A_MAX, ram)\n",
        "  trainer = Trainer(S_DIM, A_DIM, A_MAX, ram)\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  \n",
        "  trainer.load_models(400)\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  ###################################################\n",
        "  \n",
        "  prev_screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(prev_screen)\n",
        "  num_video=1\n",
        "  total_reward=0\n",
        "  ###################################################\n",
        "  for _ep in range(MAX_EPISODES):\n",
        "\n",
        "    observation = env.reset()\n",
        "    # print ('EPISODE :- ', _ep)\n",
        "    ###################################################\n",
        "    video=[]\n",
        "    total_reward=0\n",
        "    #prev_screen = env.render(mode='rgb_array')\n",
        "    #plt.imshow(prev_screen)\n",
        "    ###################################################  \n",
        "    if (_ep%10==0):\n",
        "      clear_output(wait=True)\n",
        "    for r in range(MAX_STEPS):\n",
        "      #env.render()\n",
        "      if (r%5==0 and r!=0 and _ep%100==0):\n",
        "        screen = env.render(mode='rgb_array')\n",
        "        video.append(screen)\n",
        "\n",
        "      state = np.float32(observation)\n",
        "\n",
        "      action = trainer.get_exploration_action(state)\n",
        "      # if _ep%5 == 0:\n",
        "      # \t# validate every 5th episode\n",
        "      # \taction = trainer.get_exploitation_action(state)\n",
        "      # else:\n",
        "      # \t# get action based on observation, use exploration policy here\n",
        "      # \taction = trainer.get_exploration_action(state)\n",
        "\n",
        "      new_observation, reward, done, info = env.step(action)\n",
        "\n",
        "      # # dont update if this is validation\n",
        "      # if _ep%50 == 0 or _ep>450:\n",
        "      # \tcontinue\n",
        "      ###################################################\n",
        "      total_reward+=reward\n",
        "      if (r%100==0) and (r!=0):\n",
        "        print(\"EPISODE :- \"+str(_ep)+\" STEP \"+str(r)+' REWARD '\n",
        "              +str(total_reward)+'/'+str(MAX_TOTAL_REWARD))\n",
        "        # print(\" STEP \"+str(r)+' REWARD '+str(total_reward)+'/'+str(MAX_TOTAL_REWARD))\n",
        "      \n",
        "        #plt.imshow(screen)\n",
        "        #ipythondisplay.clear_output(wait=True)\n",
        "        #ipythondisplay.display(plt.gcf())\n",
        "      \n",
        "      ###################################################\n",
        "      \n",
        "      if done:\n",
        "        new_state = None\n",
        "      else:\n",
        "        new_state = np.float32(new_observation)\n",
        "        # push this exp in ram\n",
        "        ram.add(state, action, reward, new_state)\n",
        "\n",
        "      observation = new_observation\n",
        "\n",
        "      # perform optimization\n",
        "      trainer.optimize()\n",
        "      if done: break\n",
        "\n",
        "      # check memory consumption and clear memory\n",
        "      gc.collect()\n",
        "      # process = psutil.Process(os.getpid())\n",
        "      # print(process.memory_info().rss)\n",
        "    ############################################################\n",
        "#     if _ep!=0 and _ep%int(MAX_EPISODES/quiero_n_videos)==0:\n",
        "#       file_name_temp=file_name+str(num_video)\n",
        "#       file_name_temp.replace(\" \", \"\")\n",
        "#       print(\"DDPG: Vamos a generar el video\"+file_name_temp+\".mp4\")\n",
        "#       generate_video(video,file_name_temp)\n",
        "#       print(\"DDPG: Vamos a borrar el video\"+file_name_temp+\".mp4\")\n",
        "#       deleter(len(video))\n",
        "#       try:\n",
        "#           #files.download(\"/content/\"+file_name_temp+\".mp4\")\n",
        "#           print(\"DDPG: NO Descargando...\")\n",
        "#       except:\n",
        "#           print(\"DDPG: No se pudo descargar correctamente, hágalo manual\")\n",
        "#           pass\n",
        "    if _ep%100 == 0 or total_reward>50.0:\n",
        "      #input(\"Escribe cualquier cosa\")\n",
        "      #trainer.save_models(_ep)\n",
        "      trainer.save_models(_ep)\n",
        "      print(\"DDPG: Episodio\",_ep,\"guardado\")\n",
        "    num_video+=1\n",
        "    ############################################################\n",
        "  print ('DDPG: Todos los episodios finalizados, ya se debería',\n",
        "         'haber descargado todos los videos')\n",
        "  env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W69CjO9VBNCd",
        "colab_type": "text"
      },
      "source": [
        "## ddpg_pt_to_mp4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_dLsyFZBRZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def ddpg_pt_to_mp4(file_episode=100,mini=0,just_one=0,sufijo=0):\n",
        "  env = BipedalWalkerHardcore()\n",
        "  \n",
        "  MAX_EPISODES = 1 # SOLO QUEREMOS UNA ITERACION\n",
        "  MAX_STEPS = 1000\n",
        "  MAX_BUFFER = 1000000\n",
        "  MAX_TOTAL_REWARD = 300\n",
        "  S_DIM = env.observation_space.shape[0]\n",
        "  A_DIM = env.action_space.shape[0]\n",
        "  A_MAX = env.action_space.high[0]\n",
        "\n",
        "  print(\" State Dimensions :- \", S_DIM)\n",
        "  print(\" Action Dimensions :- \", A_DIM)\n",
        "  print(\" Action Max :- \", A_MAX)\n",
        "\n",
        "  ram = MemoryBuffer(MAX_BUFFER)\n",
        "  trainer = Trainer(S_DIM, A_DIM, A_MAX, ram)\n",
        "  trainer.load_models(file_episode)# _ep+'_actor o _critic'+'.pt'\n",
        "  \n",
        "  observation = env.reset()\n",
        "  video=[]\n",
        "  total_reward=0\n",
        "  for r in range(MAX_STEPS):\n",
        "    if (r%5==0 and r!=0 ):\n",
        "      screen = env.render(mode='rgb_array')\n",
        "      video.append(screen)\n",
        "    state = np.float32(observation)\n",
        "    action = trainer.get_exploration_action(state)\n",
        "    new_observation, reward, done, info = env.step(action)\n",
        "    \n",
        "    if done:\n",
        "      new_state = None\n",
        "    else:\n",
        "      new_state = np.float32(new_observation)\n",
        "      ram.add(state, action, reward, new_state)\n",
        "    observation = new_observation\n",
        "    trainer.optimize()\n",
        "    if (r%10==0): print(\" STEP \"+str(r)+' REWARD '+str(total_reward)+'/'+str(MAX_TOTAL_REWARD))\n",
        "    total_reward+=reward\n",
        "    if done: break\n",
        "    gc.collect() \n",
        "  if mini<=total_reward or just_one==1:\n",
        "    print(\"DDPG: Vamos a generar el video\"+str(file_episode)+\"_\"+str(sufijo)+\".mp4\")\n",
        "    file_episode=file_episode+\"_\"+str(sufijo)\n",
        "    generate_video(video,str(file_episode))\n",
        "    print(\"DDPG: Vamos a borrar el video\"+str(file_episode)+\"_\"+str(sufijo)+\".mp4\")\n",
        "    deleter(len(video))\n",
        "    print ('Script finalizado c:')\n",
        "    \n",
        "  env.close()\n",
        "  return total_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UYyfjOk_PGp",
        "colab_type": "text"
      },
      "source": [
        "# Generar video en Buffer para descargar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MnvUyrVBtIw",
        "colab_type": "text"
      },
      "source": [
        "## Habilitar algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0ekLHhUEU7",
        "colab_type": "code",
        "outputId": "a6475367-e121-4106-f801-ba84934ab8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Generar video\n",
        "from google.colab import files\n",
        "  # Colab desconecta en 300 y 600 solo \n",
        "  # poner RECONECTAR y dejar que el algoritmo termine\n",
        "iniciar=0\n",
        "if iniciar==1:\n",
        "  file_name=input(\"Ingrese nombre del archivo que desea generar:\")\n",
        "  #if file_name==0: file_name=\"vid\"\n",
        "  print(\"El archivo se llamará \"+file_name+\".mp4\")\n",
        "  print(\"Ejecutando el algoritmo ...\")\n",
        "  ######################################################\n",
        "\n",
        "  # algoritmos disponibles\n",
        "  # -heuristic(file_name)\n",
        "  # -ddpg(file_name)\n",
        "  ######################################################\n",
        "\n",
        "else:\n",
        "  print(\"Cambia la variable iniciar a 1 no olvides elegir el método\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cambia la variable iniciar a 1 no olvides elegir el método\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIUgtKFFOhib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ddpg(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHJm9WgQB8cu",
        "colab_type": "text"
      },
      "source": [
        "## Generar video a partir de archivo _.pt to mp4\n",
        " No olvides subir el archivo pt a  /content/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpOSdGYd1YH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Este algotimo genera el video para el modelo de actor y critic\n",
        "# number_actor.pt\n",
        "# number_critic.pt\n",
        "# min es el minimo score que debe sacar para generar un video\n",
        "def max_reward_video():\n",
        "    max_reward=0\n",
        "    total_reward=0\n",
        "    itera=0\n",
        "    number=input(\"Ingrese número de critic y actor. Ejem: 2600   \")\n",
        "    while total_reward<90 and itera<15:\n",
        "      sufijo=itera\n",
        "      total_reward=ddpg_pt_to_mp4(number,0,1,sufijo)\n",
        "      if total_reward>total_reward:\n",
        "        max_reward=total_reward\n",
        "      print(\"MAX reward in\",str(itera),\"is\",str(max_reward))\n",
        "      itera+=1\n",
        "      print(itera)\n",
        "\n",
        "# max_reward_video()\n",
        "\n",
        "# ddpg_pt_to_mp4"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entregable_Avance_BipedalWalker.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZurMaD/BWRL/blob/master/Entregable_Avance_BipedalWalker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fz49jy4qdvL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Bipedal-Walker-Hardcore-v2\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x68hV1HFqfeS",
        "colab_type": "text"
      },
      "source": [
        "### Generar desciprción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzecRp6dqSmS",
        "colab_type": "text"
      },
      "source": [
        "## Generamos el entorno para guardar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOUth3-kqcvB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b972OCa5nDpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfIdfTQ7nEpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d1uHjWWnF5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOGwRKlfnG0K",
        "colab_type": "code",
        "outputId": "c09acd4d-2ecd-4624-871f-63ac1167e429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 600))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x600x24', ':1005'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x600x24', ':1005'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYhYFXp0oq2e",
        "colab_type": "code",
        "outputId": "4e5a9366-3209-41b1-e47d-498b67e2b376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "!pip install box2d-py\n",
        "!pip install gym[Box_2D]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.6/dist-packages (2.3.8)\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.6/dist-packages (0.10.11)\n",
            "\u001b[33m  WARNING: gym 0.10.11 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.16.3)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[Box_2D]) (1.2.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (1.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[Box_2D]) (2.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[Box_2D]) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvv06nNPvzDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# idea from\n",
        "# https://stackoverflow.com/questions/34975972/how-can-i-make-a-video-from-array-of-images-in-matplotlib\n",
        "i=1\n",
        "def deleter(num_files=100):\n",
        "  try:\n",
        "    for i in range(num_files):\n",
        "      os.system(str(\"rm /content/img%02d.png\" % i))\n",
        "      if i%50==0:\n",
        "        print(\"deleter: Se ha borrado hasta la img\",i)\n",
        "    print(\"deleter: Se ha borrado hasta la img\",i+1)\n",
        "  except Exception as e:\n",
        "    print(\"deleter\",e)\n",
        "    print(\"deleter: Algo salió mal en deleter\")\n",
        "    pass\n",
        "  #print(\"video_generado.mp4 Borrado\")\n",
        "     \n",
        "def generate_video(video,file_name):\n",
        "  try:\n",
        "    for i in range(len(video)):\n",
        "      plt.imshow(video[i])\n",
        "      plt.savefig(\"/content/img%02d.png\" % i)\n",
        "      if i%10==0:\n",
        "        print(\"generate_video: Se ha generado hasta la img\",i,\"/\",len(video))\n",
        "    print(\"generate_video: Se ha generado hasta la img\",i+1,\"/\",len(video))\n",
        "  except Exception as e:\n",
        "    print(\"generate_video\",e)\n",
        "    print(\"generate_video: Algo salió mal en generate_video\")\n",
        "    pass\n",
        "  \n",
        "  os.system(\"rm /content/\"+file_name+\".mp4\")\n",
        "  \n",
        "  \n",
        "  print(\"generate_video: Generando video...\")\n",
        "  subprocess.call([\n",
        "      'ffmpeg', '-framerate', '8', '-i', '/content/img%02d.png', '-r', '30', '-pix_fmt', 'yuv420p'\n",
        "      , file_name+'.mp4'\n",
        "  ])\n",
        "  \n",
        "\n",
        "#deleter(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLWodlzOqDbi",
        "colab_type": "text"
      },
      "source": [
        "## Importamos las librerías a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rv0MvcgqDCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import Box2D\n",
        "from Box2D.b2 import (edgeShape, circleShape, fixtureDef, polygonShape, revoluteJointDef, contactListener)\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import colorize, seeding, EzPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z0s0ernqNL8",
        "colab_type": "text"
      },
      "source": [
        "## Constantes globales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLEcgKUjqM6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is simple 4-joints walker robot environment.\n",
        "#\n",
        "# There are two versions:\n",
        "#\n",
        "# - Normal, with slightly uneven terrain.\n",
        "#\n",
        "# - Hardcore with ladders, stumps, pitfalls.\n",
        "#\n",
        "# Reward is given for moving forward, total 300+ points up to the far end. If the robot falls,\n",
        "# it gets -100. Applying motor torque costs a small amount of points, more optimal agent\n",
        "# will get better score.\n",
        "#\n",
        "# Heuristic is provided for testing, it's also useful to get demonstrations to\n",
        "# learn from. To run heuristic:\n",
        "#\n",
        "# python gym/envs/box2d/bipedal_walker.py\n",
        "#\n",
        "# State consists of hull angle speed, angular velocity, horizontal speed, vertical speed,\n",
        "# position of joints and joints angular speed, legs contact with ground, and 10 lidar\n",
        "# rangefinder measurements to help to deal with the hardcore version. There's no coordinates\n",
        "# in the state vector. Lidar is less useful in normal version, but it works.\n",
        "#\n",
        "# To solve the game you need to get 300 points in 1600 time steps.\n",
        "#\n",
        "# To solve hardcore version you need 300 points in 2000 time steps.\n",
        "#\n",
        "# Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.\n",
        "\n",
        "FPS    = 50\n",
        "SCALE  = 30.0# escalamiento para dar formas \n",
        "# affects how fast-paced the game is, forces should be adjusted as well\n",
        "\n",
        "MOTORS_TORQUE = 80\n",
        "SPEED_HIP     = 4\n",
        "SPEED_KNEE    = 6\n",
        "LIDAR_RANGE   = 160/SCALE # rango de visión del laser\n",
        "\n",
        "INITIAL_RANDOM = 5\n",
        "\n",
        "HULL_POLY =[\n",
        "    (-30,+9), (+6,+9), (+34,+1),\n",
        "    (+34,-8), (-30,-8)\n",
        "    ]#puntos para generar el body\n",
        "LEG_DOWN = -8/SCALE\n",
        "LEG_W, LEG_H = 8/SCALE, 34/SCALE\n",
        "\n",
        "VIEWPORT_W = 600\n",
        "VIEWPORT_H = 400\n",
        "\n",
        "TERRAIN_STEP   = 14/SCALE \n",
        "TERRAIN_LENGTH = 200     # in steps\n",
        "TERRAIN_HEIGHT = VIEWPORT_H/SCALE/4\n",
        "TERRAIN_GRASS    = 10    # low long are grass spots, in steps\n",
        "TERRAIN_STARTPAD = 20    # in steps\n",
        "FRICTION = 2.5\n",
        "\n",
        "HULL_FD = fixtureDef(\n",
        "                shape=polygonShape(vertices=[ (x/SCALE,y/SCALE) for x,y in HULL_POLY ]),\n",
        "                density=5.0,\n",
        "                friction=0.1,\n",
        "                categoryBits=0x0020,\n",
        "                maskBits=0x001,  # collide only with ground\n",
        "                restitution=0.0) # 0.99 bouncy\n",
        "\n",
        "LEG_FD = fixtureDef(\n",
        "                    shape=polygonShape(box=(LEG_W/2, LEG_H/2)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001)\n",
        "\n",
        "LOWER_FD = fixtureDef(\n",
        "                    shape=polygonShape(box=(0.8*LEG_W/2, LEG_H/2)),\n",
        "                    density=1.0,\n",
        "                    restitution=0.0,\n",
        "                    categoryBits=0x0020,\n",
        "                    maskBits=0x001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsfzo4CEqQec",
        "colab_type": "text"
      },
      "source": [
        "## Entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKPc9xuql4q",
        "colab_type": "text"
      },
      "source": [
        "### ContactDetector (contactListener)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0m7Gr7qpZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContactDetector(contactListener):\n",
        "    def __init__(self, env):\n",
        "        contactListener.__init__(self)\n",
        "        self.env = env\n",
        "    def BeginContact(self, contact):\n",
        "        if self.env.hull==contact.fixtureA.body or self.env.hull==contact.fixtureB.body:\n",
        "            self.env.game_over = True\n",
        "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
        "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                leg.ground_contact = True\n",
        "    def EndContact(self, contact):\n",
        "        for leg in [self.env.legs[1], self.env.legs[3]]:\n",
        "            if leg in [contact.fixtureA.body, contact.fixtureB.body]:\n",
        "                leg.ground_contact = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cISQftcyqrpK",
        "colab_type": "text"
      },
      "source": [
        "### BipedalWalker (gym.Env, EzPickle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67eQNStqq3Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BipedalWalker(gym.Env, EzPickle):\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array'],\n",
        "        'video.frames_per_second' : FPS\n",
        "    }\n",
        "\n",
        "    hardcore = False\n",
        "\n",
        "    def __init__(self):\n",
        "        EzPickle.__init__(self)\n",
        "        self.seed()\n",
        "        self.viewer = None\n",
        "\n",
        "        self.world = Box2D.b2World()\n",
        "        self.terrain = None\n",
        "        self.hull = None\n",
        "\n",
        "        self.prev_shaping = None\n",
        "\n",
        "        self.fd_polygon = fixtureDef(\n",
        "                        shape = polygonShape(vertices=\n",
        "                        [(0, 0),\n",
        "                         (1, 0),\n",
        "                         (1, -1),\n",
        "                         (0, -1)]),\n",
        "                        friction = FRICTION)\n",
        "\n",
        "        self.fd_edge = fixtureDef(\n",
        "                    shape = edgeShape(vertices=\n",
        "                    [(0, 0),\n",
        "                     (1, 1)]),\n",
        "                    friction = FRICTION,\n",
        "                    categoryBits=0x0001,\n",
        "                )\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "        high = np.array([np.inf] * 24)\n",
        "        self.action_space = spaces.Box(np.array([-1, -1, -1, -1]), np.array([1, 1, 1, 1]), dtype=np.float32)\n",
        "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def _destroy(self):\n",
        "        if not self.terrain: return\n",
        "        self.world.contactListener = None\n",
        "        for t in self.terrain:\n",
        "            self.world.DestroyBody(t)\n",
        "        self.terrain = []\n",
        "        self.world.DestroyBody(self.hull)\n",
        "        self.hull = None\n",
        "        for leg in self.legs:\n",
        "            self.world.DestroyBody(leg)\n",
        "        self.legs = []\n",
        "        self.joints = []\n",
        "\n",
        "    def _generate_terrain(self, hardcore):\n",
        "        GRASS, STUMP, STAIRS, PIT, _STATES_ = range(5)\n",
        "        state    = GRASS\n",
        "        velocity = 0.0\n",
        "        y        = TERRAIN_HEIGHT\n",
        "        counter  = TERRAIN_STARTPAD\n",
        "        oneshot  = False\n",
        "        self.terrain   = []\n",
        "        self.terrain_x = []\n",
        "        self.terrain_y = []\n",
        "        for i in range(TERRAIN_LENGTH):\n",
        "            x = i*TERRAIN_STEP\n",
        "            self.terrain_x.append(x)\n",
        "\n",
        "            if state==GRASS and not oneshot:\n",
        "                velocity = 0.8*velocity + 0.01*np.sign(TERRAIN_HEIGHT - y)\n",
        "                if i > TERRAIN_STARTPAD: velocity += self.np_random.uniform(-1, 1)/SCALE   #1\n",
        "                y += velocity\n",
        "\n",
        "            elif state==PIT and oneshot:\n",
        "                counter = self.np_random.randint(3, 5)\n",
        "                poly = [\n",
        "                    (x,              y),\n",
        "                    (x+TERRAIN_STEP, y),\n",
        "                    (x+TERRAIN_STEP, y-4*TERRAIN_STEP),\n",
        "                    (x,              y-4*TERRAIN_STEP),\n",
        "                    ]\n",
        "                self.fd_polygon.shape.vertices=poly\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "\n",
        "                self.fd_polygon.shape.vertices=[(p[0]+TERRAIN_STEP*counter,p[1]) for p in poly]\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "                counter += 2\n",
        "                original_y = y\n",
        "\n",
        "            elif state==PIT and not oneshot:\n",
        "                y = original_y\n",
        "                if counter > 1:\n",
        "                    y -= 4*TERRAIN_STEP\n",
        "\n",
        "            elif state==STUMP and oneshot:\n",
        "                counter = self.np_random.randint(1, 3)\n",
        "                poly = [\n",
        "                    (x,                      y),\n",
        "                    (x+counter*TERRAIN_STEP, y),\n",
        "                    (x+counter*TERRAIN_STEP, y+counter*TERRAIN_STEP),\n",
        "                    (x,                      y+counter*TERRAIN_STEP),\n",
        "                    ]\n",
        "                self.fd_polygon.shape.vertices=poly\n",
        "                t = self.world.CreateStaticBody(\n",
        "                    fixtures = self.fd_polygon)\n",
        "                t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                self.terrain.append(t)\n",
        "\n",
        "            elif state==STAIRS and oneshot:\n",
        "                stair_height = +1 if self.np_random.rand() > 0.5 else -1\n",
        "                stair_width = self.np_random.randint(4, 5)\n",
        "                stair_steps = self.np_random.randint(3, 5)\n",
        "                original_y = y\n",
        "                for s in range(stair_steps):\n",
        "                    poly = [\n",
        "                        (x+(    s*stair_width)*TERRAIN_STEP, y+(   s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+((1+s)*stair_width)*TERRAIN_STEP, y+(   s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+((1+s)*stair_width)*TERRAIN_STEP, y+(-1+s*stair_height)*TERRAIN_STEP),\n",
        "                        (x+(    s*stair_width)*TERRAIN_STEP, y+(-1+s*stair_height)*TERRAIN_STEP),\n",
        "                        ]\n",
        "                    self.fd_polygon.shape.vertices=poly\n",
        "                    t = self.world.CreateStaticBody(\n",
        "                        fixtures = self.fd_polygon)\n",
        "                    t.color1, t.color2 = (1,1,1), (0.6,0.6,0.6)\n",
        "                    self.terrain.append(t)\n",
        "                counter = stair_steps*stair_width\n",
        "\n",
        "            elif state==STAIRS and not oneshot:\n",
        "                s = stair_steps*stair_width - counter - stair_height\n",
        "                n = s/stair_width\n",
        "                y = original_y + (n*stair_height)*TERRAIN_STEP\n",
        "\n",
        "            oneshot = False\n",
        "            self.terrain_y.append(y)\n",
        "            counter -= 1\n",
        "            if counter==0:\n",
        "                counter = self.np_random.randint(TERRAIN_GRASS/2, TERRAIN_GRASS)\n",
        "                if state==GRASS and hardcore:\n",
        "                    state = self.np_random.randint(1, _STATES_)\n",
        "                    oneshot = True\n",
        "                else:\n",
        "                    state = GRASS\n",
        "                    oneshot = True\n",
        "\n",
        "        self.terrain_poly = []\n",
        "        for i in range(TERRAIN_LENGTH-1):\n",
        "            poly = [\n",
        "                (self.terrain_x[i],   self.terrain_y[i]),\n",
        "                (self.terrain_x[i+1], self.terrain_y[i+1])\n",
        "                ]\n",
        "            self.fd_edge.shape.vertices=poly\n",
        "            t = self.world.CreateStaticBody(\n",
        "                fixtures = self.fd_edge)\n",
        "            color = (0.3, 1.0 if i%2==0 else 0.8, 0.3)\n",
        "            t.color1 = color\n",
        "            t.color2 = color\n",
        "            self.terrain.append(t)\n",
        "            color = (0.4, 0.6, 0.3)\n",
        "            poly += [ (poly[1][0], 0), (poly[0][0], 0) ]\n",
        "            self.terrain_poly.append( (poly, color) )\n",
        "        self.terrain.reverse()\n",
        "\n",
        "    def _generate_clouds(self):\n",
        "        # Sorry for the clouds, couldn't resist\n",
        "        self.cloud_poly   = []\n",
        "        for i in range(TERRAIN_LENGTH//20):\n",
        "            x = self.np_random.uniform(0, TERRAIN_LENGTH)*TERRAIN_STEP\n",
        "            y = VIEWPORT_H/SCALE*3/4\n",
        "            poly = [\n",
        "                (x+15*TERRAIN_STEP*math.sin(3.14*2*a/5)+self.np_random.uniform(0,5*TERRAIN_STEP),\n",
        "                 y+ 5*TERRAIN_STEP*math.cos(3.14*2*a/5)+self.np_random.uniform(0,5*TERRAIN_STEP) )\n",
        "                for a in range(5) ]\n",
        "            x1 = min( [p[0] for p in poly] )\n",
        "            x2 = max( [p[0] for p in poly] )\n",
        "            self.cloud_poly.append( (poly,x1,x2) )\n",
        "\n",
        "    def reset(self):\n",
        "        self._destroy()\n",
        "        self.world.contactListener_bug_workaround = ContactDetector(self)\n",
        "        self.world.contactListener = self.world.contactListener_bug_workaround\n",
        "        self.game_over = False\n",
        "        self.prev_shaping = None\n",
        "        self.scroll = 0.0\n",
        "        self.lidar_render = 0\n",
        "\n",
        "        W = VIEWPORT_W/SCALE\n",
        "        H = VIEWPORT_H/SCALE\n",
        "\n",
        "        self._generate_terrain(self.hardcore)\n",
        "        self._generate_clouds()\n",
        "\n",
        "        init_x = TERRAIN_STEP*TERRAIN_STARTPAD/2\n",
        "        init_y = TERRAIN_HEIGHT+2*LEG_H\n",
        "        self.hull = self.world.CreateDynamicBody(\n",
        "            position = (init_x, init_y),\n",
        "            fixtures = HULL_FD\n",
        "                )\n",
        "        self.hull.color1 = (0.5,0.4,0.9)\n",
        "        self.hull.color2 = (0.3,0.3,0.5)\n",
        "        self.hull.ApplyForceToCenter((self.np_random.uniform(-INITIAL_RANDOM, INITIAL_RANDOM), 0), True)\n",
        "\n",
        "        self.legs = []\n",
        "        self.joints = []\n",
        "        for i in [-1,+1]:\n",
        "            leg = self.world.CreateDynamicBody(\n",
        "                position = (init_x, init_y - LEG_H/2 - LEG_DOWN),\n",
        "                angle = (i*0.05),\n",
        "                fixtures = LEG_FD\n",
        "                )\n",
        "            leg.color1 = (0.6-i/10., 0.3-i/10., 0.5-i/10.)\n",
        "            leg.color2 = (0.4-i/10., 0.2-i/10., 0.3-i/10.)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=self.hull,\n",
        "                bodyB=leg,\n",
        "                localAnchorA=(0, LEG_DOWN),\n",
        "                localAnchorB=(0, LEG_H/2),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=MOTORS_TORQUE,\n",
        "                motorSpeed = i,\n",
        "                lowerAngle = -0.8,\n",
        "                upperAngle = 1.1,\n",
        "                )\n",
        "            self.legs.append(leg)\n",
        "            self.joints.append(self.world.CreateJoint(rjd))\n",
        "\n",
        "            lower = self.world.CreateDynamicBody(\n",
        "                position = (init_x, init_y - LEG_H*3/2 - LEG_DOWN),\n",
        "                angle = (i*0.05),\n",
        "                fixtures = LOWER_FD\n",
        "                )\n",
        "            lower.color1 = (0.6-i/10., 0.3-i/10., 0.5-i/10.)\n",
        "            lower.color2 = (0.4-i/10., 0.2-i/10., 0.3-i/10.)\n",
        "            rjd = revoluteJointDef(\n",
        "                bodyA=leg,\n",
        "                bodyB=lower,\n",
        "                localAnchorA=(0, -LEG_H/2),\n",
        "                localAnchorB=(0, LEG_H/2),\n",
        "                enableMotor=True,\n",
        "                enableLimit=True,\n",
        "                maxMotorTorque=MOTORS_TORQUE,\n",
        "                motorSpeed = 1,\n",
        "                lowerAngle = -1.6,\n",
        "                upperAngle = -0.1,\n",
        "                )\n",
        "            lower.ground_contact = False\n",
        "            self.legs.append(lower)\n",
        "            self.joints.append(self.world.CreateJoint(rjd))\n",
        "\n",
        "        self.drawlist = self.terrain + self.legs + [self.hull]\n",
        "\n",
        "        class LidarCallback(Box2D.b2.rayCastCallback):\n",
        "            def ReportFixture(self, fixture, point, normal, fraction):\n",
        "                if (fixture.filterData.categoryBits & 1) == 0:\n",
        "                    return 1\n",
        "                self.p2 = point\n",
        "                self.fraction = fraction\n",
        "                return 0\n",
        "        self.lidar = [LidarCallback() for _ in range(10)]\n",
        "\n",
        "        return self.step(np.array([0,0,0,0]))[0]\n",
        "\n",
        "    def step(self, action):\n",
        "        #self.hull.ApplyForceToCenter((0, 20), True) -- Uncomment this to receive a bit of stability help\n",
        "        control_speed = False  # Should be easier as well\n",
        "        if control_speed:\n",
        "            self.joints[0].motorSpeed = float(SPEED_HIP  * np.clip(action[0], -1, 1))\n",
        "            self.joints[1].motorSpeed = float(SPEED_KNEE * np.clip(action[1], -1, 1))\n",
        "            self.joints[2].motorSpeed = float(SPEED_HIP  * np.clip(action[2], -1, 1))\n",
        "            self.joints[3].motorSpeed = float(SPEED_KNEE * np.clip(action[3], -1, 1))\n",
        "        else:\n",
        "            self.joints[0].motorSpeed     = float(SPEED_HIP     * np.sign(action[0]))\n",
        "            self.joints[0].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[0]), 0, 1))\n",
        "            self.joints[1].motorSpeed     = float(SPEED_KNEE    * np.sign(action[1]))\n",
        "            self.joints[1].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[1]), 0, 1))\n",
        "            self.joints[2].motorSpeed     = float(SPEED_HIP     * np.sign(action[2]))\n",
        "            self.joints[2].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[2]), 0, 1))\n",
        "            self.joints[3].motorSpeed     = float(SPEED_KNEE    * np.sign(action[3]))\n",
        "            self.joints[3].maxMotorTorque = float(MOTORS_TORQUE * np.clip(np.abs(action[3]), 0, 1))\n",
        "\n",
        "        self.world.Step(1.0/FPS, 6*30, 2*30)\n",
        "\n",
        "        pos = self.hull.position\n",
        "        vel = self.hull.linearVelocity\n",
        "\n",
        "        for i in range(10):\n",
        "            self.lidar[i].fraction = 1.0\n",
        "            self.lidar[i].p1 = pos\n",
        "            self.lidar[i].p2 = (\n",
        "                pos[0] + math.sin(1.5*i/10.0)*LIDAR_RANGE,\n",
        "                pos[1] - math.cos(1.5*i/10.0)*LIDAR_RANGE)\n",
        "            self.world.RayCast(self.lidar[i], self.lidar[i].p1, self.lidar[i].p2)\n",
        "\n",
        "        state = [\n",
        "            self.hull.angle,        # Normal angles up to 0.5 here, but sure more is possible.\n",
        "            2.0*self.hull.angularVelocity/FPS,\n",
        "            0.3*vel.x*(VIEWPORT_W/SCALE)/FPS,  # Normalized to get -1..1 range\n",
        "            0.3*vel.y*(VIEWPORT_H/SCALE)/FPS,\n",
        "            self.joints[0].angle,   # This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)\n",
        "            self.joints[0].speed / SPEED_HIP,\n",
        "            self.joints[1].angle + 1.0,\n",
        "            self.joints[1].speed / SPEED_KNEE,\n",
        "            1.0 if self.legs[1].ground_contact else 0.0,\n",
        "            self.joints[2].angle,\n",
        "            self.joints[2].speed / SPEED_HIP,\n",
        "            self.joints[3].angle + 1.0,\n",
        "            self.joints[3].speed / SPEED_KNEE,\n",
        "            1.0 if self.legs[3].ground_contact else 0.0\n",
        "            ]\n",
        "        state += [l.fraction for l in self.lidar]\n",
        "        assert len(state)==24\n",
        "\n",
        "        self.scroll = pos.x - VIEWPORT_W/SCALE/5\n",
        "\n",
        "        shaping  = 130*pos[0]/SCALE   # moving forward is a way to receive reward (normalized to get 300 on completion)\n",
        "        shaping -= 5.0*abs(state[0])  # keep head straight, other than that and falling, any behavior is unpunished\n",
        "\n",
        "        reward = 0\n",
        "        if self.prev_shaping is not None:\n",
        "            reward = shaping - self.prev_shaping\n",
        "        self.prev_shaping = shaping\n",
        "\n",
        "        for a in action:\n",
        "            reward -= 0.00035 * MOTORS_TORQUE * np.clip(np.abs(a), 0, 1)\n",
        "            # normalized to about -50.0 using heuristic, more optimal agent should spend less\n",
        "\n",
        "        done = False\n",
        "        if self.game_over or pos[0] < 0:\n",
        "            reward = -100\n",
        "            done   = True\n",
        "        if pos[0] > (TERRAIN_LENGTH-TERRAIN_GRASS)*TERRAIN_STEP:\n",
        "            done   = True\n",
        "        return np.array(state), reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        from gym.envs.classic_control import rendering\n",
        "        if self.viewer is None:\n",
        "            self.viewer = rendering.Viewer(VIEWPORT_W, VIEWPORT_H)\n",
        "        self.viewer.set_bounds(self.scroll, VIEWPORT_W/SCALE + self.scroll, 0, VIEWPORT_H/SCALE)\n",
        "\n",
        "        self.viewer.draw_polygon( [\n",
        "            (self.scroll,                  0),\n",
        "            (self.scroll+VIEWPORT_W/SCALE, 0),\n",
        "            (self.scroll+VIEWPORT_W/SCALE, VIEWPORT_H/SCALE),\n",
        "            (self.scroll,                  VIEWPORT_H/SCALE),\n",
        "            ], color=(0.9, 0.9, 1.0) )\n",
        "        for poly,x1,x2 in self.cloud_poly:\n",
        "            if x2 < self.scroll/2: continue\n",
        "            if x1 > self.scroll/2 + VIEWPORT_W/SCALE: continue\n",
        "            self.viewer.draw_polygon( [(p[0]+self.scroll/2, p[1]) for p in poly], color=(1,1,1))\n",
        "        for poly, color in self.terrain_poly:\n",
        "            if poly[1][0] < self.scroll: continue\n",
        "            if poly[0][0] > self.scroll + VIEWPORT_W/SCALE: continue\n",
        "            self.viewer.draw_polygon(poly, color=color)\n",
        "\n",
        "        self.lidar_render = (self.lidar_render+1) % 100\n",
        "        i = self.lidar_render\n",
        "        if i < 2*len(self.lidar):\n",
        "            l = self.lidar[i] if i < len(self.lidar) else self.lidar[len(self.lidar)-i-1]\n",
        "            self.viewer.draw_polyline( [l.p1, l.p2], color=(1,0,0), linewidth=1 )\n",
        "\n",
        "        for obj in self.drawlist:\n",
        "            for f in obj.fixtures:\n",
        "                trans = f.body.transform\n",
        "                if type(f.shape) is circleShape:\n",
        "                    t = rendering.Transform(translation=trans*f.shape.pos)\n",
        "                    self.viewer.draw_circle(f.shape.radius, 30, color=obj.color1).add_attr(t)\n",
        "                    self.viewer.draw_circle(f.shape.radius, 30, color=obj.color2, filled=False, linewidth=2).add_attr(t)\n",
        "                else:\n",
        "                    path = [trans*v for v in f.shape.vertices]\n",
        "                    self.viewer.draw_polygon(path, color=obj.color1)\n",
        "                    path.append(path[0])\n",
        "                    self.viewer.draw_polyline(path, color=obj.color2, linewidth=2)\n",
        "\n",
        "        flagy1 = TERRAIN_HEIGHT\n",
        "        flagy2 = flagy1 + 50/SCALE\n",
        "        x = TERRAIN_STEP*3\n",
        "        self.viewer.draw_polyline( [(x, flagy1), (x, flagy2)], color=(0,0,0), linewidth=2 )\n",
        "        f = [(x, flagy2), (x, flagy2-10/SCALE), (x+25/SCALE, flagy2-5/SCALE)]\n",
        "        self.viewer.draw_polygon(f, color=(0.9,0.2,0) )\n",
        "        self.viewer.draw_polyline(f + [f[0]], color=(0,0,0), linewidth=2 )\n",
        "\n",
        "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "            self.viewer = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJKGn0VAq7QK",
        "colab_type": "text"
      },
      "source": [
        "### Clase BipedalWalkerHardcore(BipedalWalker)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX6rnTXdq6y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BipedalWalkerHardcore(BipedalWalker):\n",
        "    hardcore = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Xp71dWq_9L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# heuristic()\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqezS0Aloblq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if __name__==\"__main__\":\n",
        "\n",
        "def heuristic(file_name=\"video\"):  \n",
        "  \n",
        "  # Heurisic: suboptimal, have no notion of balance.\n",
        "  env = BipedalWalkerHardcore() #Aquí se elige que entorno será\n",
        "  env.reset()\n",
        "\n",
        "  ###################################################\n",
        "  video=[]\n",
        "  prev_screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(prev_screen)\n",
        "  image=0\n",
        "  ###################################################\n",
        "  \n",
        "  steps = 0\n",
        "  total_reward = 0\n",
        "  a = np.array([0.0, 0.0, 0.0, 0.0])\n",
        "  STAY_ON_ONE_LEG, PUT_OTHER_DOWN, PUSH_OFF = 1,2,3\n",
        "  SPEED = 0.29  # Will fall forward on higher speed\n",
        "  state = STAY_ON_ONE_LEG\n",
        "  moving_leg = 0\n",
        "  supporting_leg = 1 - moving_leg\n",
        "  SUPPORT_KNEE_ANGLE = +0.1\n",
        "  supporting_knee_angle = SUPPORT_KNEE_ANGLE\n",
        "  \n",
        "  while True: \n",
        "    ###################################################\n",
        "    image += 1\n",
        "    ###################################################\n",
        "    s, r, done, info = env.step(a)\n",
        "\n",
        "    total_reward += r\n",
        "    #if steps % 20 == 0 or done:\n",
        "    #    print(\"\\naction \" + str([\"{:+0.2f}\".format(x) for x in a]))\n",
        "    #    print(\"step {} total_reward {:+0.2f}\".format(steps, total_reward))\n",
        "    #    print(\"hull \" + str([\"{:+0.2f}\".format(x) for x in s[0:4] ]))\n",
        "    #    print(\"leg0 \" + str([\"{:+0.2f}\".format(x) for x in s[4:9] ]))\n",
        "    #    print(\"leg1 \" + str([\"{:+0.2f}\".format(x) for x in s[9:14]]))\n",
        "    steps += 1\n",
        "\n",
        "    contact0 = s[8]\n",
        "    contact1 = s[13]\n",
        "    moving_s_base = 4 + 5*moving_leg\n",
        "    supporting_s_base = 4 + 5*supporting_leg\n",
        "\n",
        "    hip_targ  = [None,None]   # -0.8 .. +1.1\n",
        "    knee_targ = [None,None]   # -0.6 .. +0.9\n",
        "    hip_todo  = [0.0, 0.0]\n",
        "    knee_todo = [0.0, 0.0]\n",
        "\n",
        "    if state==STAY_ON_ONE_LEG:\n",
        "        hip_targ[moving_leg]  = 1.1\n",
        "        knee_targ[moving_leg] = -0.6\n",
        "        supporting_knee_angle += 0.03\n",
        "        if s[2] > SPEED: supporting_knee_angle += 0.03\n",
        "        supporting_knee_angle = min( supporting_knee_angle, SUPPORT_KNEE_ANGLE )\n",
        "        knee_targ[supporting_leg] = supporting_knee_angle\n",
        "        if s[supporting_s_base+0] < 0.10: # supporting leg is behind\n",
        "            state = PUT_OTHER_DOWN\n",
        "    if state==PUT_OTHER_DOWN:\n",
        "        hip_targ[moving_leg]  = +0.1\n",
        "        knee_targ[moving_leg] = SUPPORT_KNEE_ANGLE\n",
        "        knee_targ[supporting_leg] = supporting_knee_angle\n",
        "        if s[moving_s_base+4]:\n",
        "            state = PUSH_OFF\n",
        "            supporting_knee_angle = min( s[moving_s_base+2], SUPPORT_KNEE_ANGLE )\n",
        "    if state==PUSH_OFF:\n",
        "        knee_targ[moving_leg] = supporting_knee_angle\n",
        "        knee_targ[supporting_leg] = +1.0\n",
        "        if s[supporting_s_base+2] > 0.88 or s[2] > 1.2*SPEED:\n",
        "            state = STAY_ON_ONE_LEG\n",
        "            moving_leg = 1 - moving_leg\n",
        "            supporting_leg = 1 - moving_leg\n",
        "\n",
        "    if hip_targ[0]: hip_todo[0] = 0.9*(hip_targ[0] - s[4]) - 0.25*s[5]\n",
        "    if hip_targ[1]: hip_todo[1] = 0.9*(hip_targ[1] - s[9]) - 0.25*s[10]\n",
        "    if knee_targ[0]: knee_todo[0] = 4.0*(knee_targ[0] - s[6])  - 0.25*s[7]\n",
        "    if knee_targ[1]: knee_todo[1] = 4.0*(knee_targ[1] - s[11]) - 0.25*s[12]\n",
        "\n",
        "    hip_todo[0] -= 0.9*(0-s[0]) - 1.5*s[1] # PID to keep head strait\n",
        "    hip_todo[1] -= 0.9*(0-s[0]) - 1.5*s[1]\n",
        "    knee_todo[0] -= 15.0*s[3]  # vertical speed, to damp oscillations\n",
        "    knee_todo[1] -= 15.0*s[3]\n",
        "\n",
        "    a[0] = hip_todo[0]\n",
        "    a[1] = knee_todo[0]\n",
        "    a[2] = hip_todo[1]\n",
        "    a[3] = knee_todo[1]\n",
        "    a = np.clip(0.5*a, -1.0, 1.0)\n",
        "\n",
        "\n",
        "    ###################################################\n",
        "    if image%5==0: #Cada cuántas acciones renderizamos\n",
        "      screen = env.render(mode='rgb_array')\n",
        "      video.append(screen)\n",
        "      #plt.imshow(screen)\n",
        "      #ipythondisplay.clear_output(wait=True)\n",
        "      #ipythondisplay.display(plt.gcf())\n",
        "    ###################################################\n",
        "\n",
        "    if done: \n",
        "      video.append(screen) \n",
        "      break\n",
        "  #ipythondisplay.clear_output(wait=True)\n",
        "  env.close()\n",
        "  generate_video(video,file_name)\n",
        "  print(\"Video generado, se muestra el frame final\")\n",
        "  deleter(len(video))\n",
        "  try:\n",
        "    files.download(\"/content/\"+file_name+\".mp4\")\n",
        "  except:\n",
        "    print(\"No se pudo descargar correctamente, hágalo manual\")\n",
        "    pass\n",
        "  print(\"Descargando...\")\n",
        "  return (\"Heuristic finalizado\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vas1vRUt62Wg",
        "colab_type": "text"
      },
      "source": [
        "### Generar video en real time (No recomendado)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv-tYTCc6Gwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(video)):\n",
        "#  plt.imshow(video[i])  \n",
        "#  ipythondisplay.display(plt.gcf())\n",
        "#  ipythondisplay.clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI1j_cjAW01u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ddpg()\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://github.com/vy007vikas/PyTorch-ActorCriticRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfY-ALUOXTJO",
        "colab_type": "text"
      },
      "source": [
        "## Instalando PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dPJZNHnW5ID",
        "colab_type": "code",
        "outputId": "e507b1a4-0049-436c-ac56-ee0e793216f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 from https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.16.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5bGYQEPXWqe",
        "colab_type": "text"
      },
      "source": [
        "## Habilitando uso de GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU5TA8NzXeqY",
        "colab_type": "text"
      },
      "source": [
        "Idea from https://colab.research.google.com/drive/1jxUPzMsAkBboHMQtGyfv5M5c7hU8Ss2c#scrollTo=oQ6isf-kI2HD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldvKWUhkdSTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ORIGINAL ESCRITO EN .PY\n",
        "#MAIN.PY\n",
        "from __future__ import division\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import psutil\n",
        "import gc\n",
        "\n",
        "#import train\n",
        "#import buffer\n",
        "\n",
        "#BUFFER.PY\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "#MODEL.PY\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "#TRAIN.PY\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#import utils\n",
        "#import model\n",
        "\n",
        "\n",
        "#IMPORT UTILS\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import shutil\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3_1mBxQUhi",
        "colab_type": "text"
      },
      "source": [
        "## BUFFER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilYvZFyeWjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BUFFER\n",
        "class MemoryBuffer:\n",
        "\n",
        "\tdef __init__(self, size):\n",
        "\t\tself.buffer = deque(maxlen=size)\n",
        "\t\tself.maxSize = size\n",
        "\t\tself.len = 0\n",
        "\n",
        "\tdef sample(self, count):\n",
        "\t\t\"\"\"\n",
        "\t\tsamples a random batch from the replay memory buffer\n",
        "\t\t:param count: batch size\n",
        "\t\t:return: batch (numpy array)\n",
        "\t\t\"\"\"\n",
        "\t\tbatch = []\n",
        "\t\tcount = min(count, self.len)\n",
        "\t\tbatch = random.sample(self.buffer, count)\n",
        "\n",
        "\t\ts_arr = np.float32([arr[0] for arr in batch])\n",
        "\t\ta_arr = np.float32([arr[1] for arr in batch])\n",
        "\t\tr_arr = np.float32([arr[2] for arr in batch])\n",
        "\t\ts1_arr = np.float32([arr[3] for arr in batch])\n",
        "\n",
        "\t\treturn s_arr, a_arr, r_arr, s1_arr\n",
        "\n",
        "\tdef len(self):\n",
        "\t\treturn self.len\n",
        "\n",
        "\tdef add(self, s, a, r, s1):\n",
        "\t\t\"\"\"\n",
        "\t\tadds a particular transaction in the memory buffer\n",
        "\t\t:param s: current state\n",
        "\t\t:param a: action taken\n",
        "\t\t:param r: reward received\n",
        "\t\t:param s1: next state\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\ttransition = (s,a,r,s1)\n",
        "\t\tself.len += 1\n",
        "\t\tif self.len > self.maxSize:\n",
        "\t\t\tself.len = self.maxSize\n",
        "\t\tself.buffer.append(transition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McIsP5dAQWK2",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85vC4VM-eiGs",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "# MODEL\n",
        "EPS = 0.003\n",
        "\n",
        "def fanin_init(size, fanin=None):\n",
        "\tfanin = fanin or size[0]\n",
        "\tv = 1. / np.sqrt(fanin)\n",
        "\treturn torch.Tensor(size).uniform_(-v, v)\n",
        "\n",
        "class Critic(nn.Module):\n",
        "\n",
        "\tdef __init__(self, state_dim, action_dim):\n",
        "\t\t\"\"\"\n",
        "\t\t:param state_dim: Dimension of input state (int)\n",
        "\t\t:param action_dim: Dimension of input action (int)\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Critic, self).__init__()\n",
        "\n",
        "\t\tself.state_dim = state_dim\n",
        "\t\tself.action_dim = action_dim\n",
        "\n",
        "\t\tself.fcs1 = nn.Linear(state_dim,256)\n",
        "\t\tself.fcs1.weight.data = fanin_init(self.fcs1.weight.data.size())\n",
        "\t\tself.fcs2 = nn.Linear(256,128)\n",
        "\t\tself.fcs2.weight.data = fanin_init(self.fcs2.weight.data.size())\n",
        "\n",
        "\t\tself.fca1 = nn.Linear(action_dim,128)\n",
        "\t\tself.fca1.weight.data = fanin_init(self.fca1.weight.data.size())\n",
        "\n",
        "\t\tself.fc2 = nn.Linear(256,128)\n",
        "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
        "\n",
        "\t\tself.fc3 = nn.Linear(128,1)\n",
        "\t\tself.fc3.weight.data.uniform_(-EPS,EPS)\n",
        "\n",
        "\tdef forward(self, state, action):\n",
        "\t\t\"\"\"\n",
        "\t\treturns Value function Q(s,a) obtained from critic network\n",
        "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
        "\t\t:param action: Input Action (Torch Variable : [n,action_dim] )\n",
        "\t\t:return: Value function : Q(S,a) (Torch Variable : [n,1] )\n",
        "\t\t\"\"\"\n",
        "\t\ts1 = F.relu(self.fcs1(state))\n",
        "\t\ts2 = F.relu(self.fcs2(s1))\n",
        "\t\ta1 = F.relu(self.fca1(action))\n",
        "\t\tx = torch.cat((s2,a1),dim=1)\n",
        "\n",
        "\t\tx = F.relu(self.fc2(x))\n",
        "\t\tx = self.fc3(x)\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Actor(nn.Module):\n",
        "\n",
        "\tdef __init__(self, state_dim, action_dim, action_lim):\n",
        "\t\t\"\"\"\n",
        "\t\t:param state_dim: Dimension of input state (int)\n",
        "\t\t:param action_dim: Dimension of output action (int)\n",
        "\t\t:param action_lim: Used to limit action in [-action_lim,action_lim]\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(Actor, self).__init__()\n",
        "\n",
        "\t\tself.state_dim = state_dim\n",
        "\t\tself.action_dim = action_dim\n",
        "\t\tself.action_lim = action_lim\n",
        "\n",
        "\t\tself.fc1 = nn.Linear(state_dim,256)\n",
        "\t\tself.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
        "\n",
        "\t\tself.fc2 = nn.Linear(256,128)\n",
        "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
        "\n",
        "\t\tself.fc3 = nn.Linear(128,64)\n",
        "\t\tself.fc3.weight.data = fanin_init(self.fc3.weight.data.size())\n",
        "\n",
        "\t\tself.fc4 = nn.Linear(64,action_dim)\n",
        "\t\tself.fc4.weight.data.uniform_(-EPS,EPS)\n",
        "\n",
        "\tdef forward(self, state):\n",
        "\t\t\"\"\"\n",
        "\t\treturns policy function Pi(s) obtained from actor network\n",
        "\t\tthis function is a gaussian prob distribution for all actions\n",
        "\t\twith mean lying in (-1,1) and sigma lying in (0,1)\n",
        "\t\tThe sampled action can , then later be rescaled\n",
        "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
        "\t\t:return: Output action (Torch Variable: [n,action_dim] )\n",
        "\t\t\"\"\"\n",
        "\t\tx = F.relu(self.fc1(state))\n",
        "\t\tx = F.relu(self.fc2(x))\n",
        "\t\tx = F.relu(self.fc3(x))\n",
        "\t\taction = F.tanh(self.fc4(x))\n",
        "\n",
        "\t\taction = action * self.action_lim\n",
        "\n",
        "\t\treturn action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBYKy2ZIQXo6",
        "colab_type": "text"
      },
      "source": [
        "## TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eRqqAH0elgE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# TRAINER\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "GAMMA = 0.99\n",
        "TAU = 0.001\n",
        "class Trainer():\n",
        "  \n",
        "  def __init__(self, state_dim, action_dim, action_lim, ram):\n",
        "    #\"\"\"\n",
        "    #param state_dim: Dimensions of state (int)\n",
        "    #param action_dim: Dimension of action (int)\n",
        "    #param action_lim: Used to limit action in [-action_lim,action_lim]\n",
        "    #param ram: replay memory buffer object\n",
        "    #return\n",
        "    #\"\"\"\n",
        "    self.state_dim = state_dim\n",
        "    self.action_dim = action_dim\n",
        "    self.action_lim = action_lim\n",
        "    self.ram = ram\n",
        "    self.iter = 0\n",
        "    #self.noise = utils.OrnsteinUhlenbeckActionNoise(self.action_dim)\n",
        "    self.noise = OrnsteinUhlenbeckActionNoise(self.action_dim)    \n",
        "\n",
        "    #self.actor = model.Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.actor = Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    #self.target_actor = model.Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.target_actor = Actor(self.state_dim, self.action_dim, self.action_lim)\n",
        "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),LEARNING_RATE)\n",
        "\n",
        "    #self.critic = model.Critic(self.state_dim, self.action_dim)\n",
        "    self.critic = Critic(self.state_dim, self.action_dim)\n",
        "    #self.target_critic = model.Critic(self.state_dim, self.action_dim)\n",
        "    self.target_critic = Critic(self.state_dim, self.action_dim)\n",
        "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),LEARNING_RATE)\n",
        "\n",
        "    #utils.hard_update(self.target_actor, self.actor)\n",
        "    hard_update(self.target_actor, self.actor)\n",
        "    #utils.hard_update(self.target_critic, self.critic)\n",
        "    hard_update(self.target_critic, self.critic)\n",
        "  def get_exploitation_action(self,state):\n",
        "    #\"\"\"\n",
        "    #gets the action from target actor added with exploration noise\n",
        "    #:param state: state (Numpy array)\n",
        "    #:return: sampled action (Numpy array)\n",
        "    #\"\"\"\n",
        "    state = Variable(torch.from_numpy(state))\n",
        "    action = self.target_actor.forward(state).detach()\n",
        "    return action.data.numpy()\n",
        "  def get_exploration_action(self,state):\n",
        "    #\"\"\"\n",
        "    #gets the action from actor added with exploration noise\n",
        "    #:param state: state (Numpy array)\n",
        "    #:return: sampled action (Numpy array)\n",
        "    #\"\"\"\n",
        "    state = Variable(torch.from_numpy(state))\n",
        "    action = self.actor.forward(state).detach()\n",
        "    new_action = action.data.numpy() + (self.noise.sample() * self.action_lim)\n",
        "    return new_action\n",
        "  def optimize(self):\n",
        "    #\"\"\"\n",
        "    #Samples a random batch from replay memory and performs optimization\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    s1,a1,r1,s2 = self.ram.sample(BATCH_SIZE)\n",
        "\n",
        "    s1 = Variable(torch.from_numpy(s1))\n",
        "    a1 = Variable(torch.from_numpy(a1))\n",
        "    r1 = Variable(torch.from_numpy(r1))\n",
        "    s2 = Variable(torch.from_numpy(s2))\n",
        "\n",
        "    # ---------------------- optimize critic ----------------------\n",
        "    # Use target actor exploitation policy here for loss evaluation\n",
        "    a2 = self.target_actor.forward(s2).detach()\n",
        "    next_val = torch.squeeze(self.target_critic.forward(s2, a2).detach())\n",
        "    # y_exp = r + gamma*Q'( s2, pi'(s2))\n",
        "    y_expected = r1 + GAMMA*next_val\n",
        "    # y_pred = Q( s1, a1)\n",
        "    y_predicted = torch.squeeze(self.critic.forward(s1, a1))\n",
        "    # compute critic loss, and update the critic\n",
        "    loss_critic = F.smooth_l1_loss(y_predicted, y_expected)\n",
        "    self.critic_optimizer.zero_grad()\n",
        "    loss_critic.backward()\n",
        "    self.critic_optimizer.step()\n",
        "\n",
        "    # ---------------------- optimize actor ----------------------\n",
        "    pred_a1 = self.actor.forward(s1)\n",
        "    loss_actor = -1*torch.sum(self.critic.forward(s1, pred_a1))\n",
        "    self.actor_optimizer.zero_grad()\n",
        "    loss_actor.backward()\n",
        "    self.actor_optimizer.step()\n",
        "\n",
        "    #utils.soft_update(self.target_actor, self.actor, TAU)\n",
        "    soft_update(self.target_actor, self.actor, TAU)\n",
        "    #utils.soft_update(self.target_critic, self.critic, TAU)\n",
        "    soft_update(self.target_critic, self.critic, TAU)\n",
        "\n",
        "    # if self.iter % 100 == 0:\n",
        "    # \tprint 'Iteration :- ', self.iter, ' Loss_actor :- ', loss_actor.data.numpy(),\\\n",
        "    # \t\t' Loss_critic :- ', loss_critic.data.numpy()\n",
        "    # self.iter += 1\n",
        "  def save_models(self, episode_count):\n",
        "    #\"\"\"\n",
        "    #saves the target actor and critic models\n",
        "    #:param episode_count: the count of episodes iterated\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    torch.save(self.target_actor.state_dict(), '/content/' + str(episode_count) + '_actor.pt')\n",
        "    # Cambiamos dónde se guarda a content, anteriormente en Models\n",
        "    torch.save(self.target_critic.state_dict(), '/content/' + str(episode_count) + '_critic.pt')\n",
        "    print ('save_models: Models saved successfully')\n",
        "\n",
        "  def load_models(self, episode):\n",
        "    #\"\"\"\n",
        "    #loads the target actor and critic models, and copies them onto actor and critic models\n",
        "    #:param episode: the count of episodes iterated (used to find the file name)\n",
        "    #:return:\n",
        "    #\"\"\"\n",
        "    self.actor.load_state_dict(torch.load('/content/' + str(episode) + '_actor.pt'))\n",
        "    self.critic.load_state_dict(torch.load('/content/' + str(episode) + '_critic.pt'))\n",
        "    #utils.hard_update(self.target_actor, self.actor)\n",
        "    hard_update(self.target_actor, self.actor)\n",
        "    #utils.hard_update(self.target_critic, self.critic)\n",
        "    hard_update(self.target_critic, self.critic)\n",
        "    print ('save_models: Models loaded succesfully')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-gILeJFQY2y",
        "colab_type": "text"
      },
      "source": [
        "## UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ewoApuepU0",
        "colab_type": "code",
        "outputId": "16ad030f-f8dd-4de0-9089-d49749779e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# UTILS\n",
        "def soft_update(target, source, tau):\n",
        "\t\"\"\"\n",
        "\tCopies the parameters from source network (x) to target network (y) using the below update\n",
        "\ty = TAU*x + (1 - TAU)*y\n",
        "\t:param target: Target network (PyTorch)\n",
        "\t:param source: Source network (PyTorch)\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
        "\t\ttarget_param.data.copy_(\n",
        "\t\t\ttarget_param.data * (1.0 - tau) + param.data * tau\n",
        "\t\t)\n",
        "\n",
        "\n",
        "def hard_update(target, source):\n",
        "\t\"\"\"\n",
        "\tCopies the parameters from source network to target network\n",
        "\t:param target: Target network (PyTorch)\n",
        "\t:param source: Source network (PyTorch)\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
        "\t\t\ttarget_param.data.copy_(param.data)\n",
        "\n",
        "\n",
        "def save_training_checkpoint(state, is_best, episode_count):\n",
        "\t\"\"\"\n",
        "\tSaves the models, with all training parameters intact\n",
        "\t:param state:\n",
        "\t:param is_best:\n",
        "\t:param filename:\n",
        "\t:return:\n",
        "\t\"\"\"\n",
        "\tfilename = str(episode_count) + 'checkpoint.path.rar'\n",
        "\ttorch.save(state, filename)\n",
        "\tif is_best:\n",
        "\t\tshutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
        "class OrnsteinUhlenbeckActionNoise:\n",
        "\n",
        "\tdef __init__(self, action_dim, mu = 0, theta = 0.15, sigma = 0.2):\n",
        "\t\tself.action_dim = action_dim\n",
        "\t\tself.mu = mu\n",
        "\t\tself.theta = theta\n",
        "\t\tself.sigma = sigma\n",
        "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
        "\n",
        "\tdef sample(self):\n",
        "\t\tdx = self.theta * (self.mu - self.X)\n",
        "\t\tdx = dx + self.sigma * np.random.randn(len(self.X))\n",
        "\t\tself.X = self.X + dx\n",
        "\t\treturn self.X\n",
        "\n",
        "\n",
        "# use this to plot Ornstein Uhlenbeck random motion\n",
        "if __name__ == '__main__':\n",
        "\tou = OrnsteinUhlenbeckActionNoise(1)\n",
        "\tstates = []\n",
        "\tfor i in range(1000):\n",
        "\t\tstates.append(ou.sample())\n",
        "\timport matplotlib.pyplot as plt\n",
        "\n",
        "\tplt.plot(states)\n",
        "\tplt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klzEjv3lQaii",
        "colab_type": "text"
      },
      "source": [
        "## MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKwwBc1-etWV",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# MAIN\n",
        "##############################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "##############################################\n",
        "def ddpg(file_name=\"video\"):\n",
        "  env = BipedalWalkerHardcore() #Aquí se elige que entorno será\n",
        "  env.reset()\n",
        "  ################################\n",
        "  quiero_n_videos=100\n",
        "  ###############################\n",
        "  MAX_EPISODES = 3000\n",
        "  MAX_STEPS = 1000\n",
        "  MAX_BUFFER = 1000000\n",
        "  MAX_TOTAL_REWARD = 300\n",
        "  S_DIM = env.observation_space.shape[0]\n",
        "  A_DIM = env.action_space.shape[0]\n",
        "  A_MAX = env.action_space.high[0]\n",
        "\n",
        "  print(\" State Dimensions :- \", S_DIM)\n",
        "  print(\" Action Dimensions :- \", A_DIM)\n",
        "  print(\" Action Max :- \", A_MAX)\n",
        "\n",
        "  #ram = buffer.MemoryBuffer(MAX_BUFFER)\n",
        "  ram = MemoryBuffer(MAX_BUFFER)\n",
        "  #trainer = train.Trainer(S_DIM, A_DIM, A_MAX, ram)\n",
        "  trainer = Trainer(S_DIM, A_DIM, A_MAX, ram)\n",
        "\n",
        "  ###################################################\n",
        "  prev_screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(prev_screen)\n",
        "  num_video=1\n",
        "  ###################################################\n",
        "  for _ep in range(MAX_EPISODES):\n",
        "\n",
        "    observation = env.reset()\n",
        "    # print ('EPISODE :- ', _ep)\n",
        "    ###################################################\n",
        "    video=[]\n",
        "    #prev_screen = env.render(mode='rgb_array')\n",
        "    #plt.imshow(prev_screen)\n",
        "    ###################################################  \n",
        "    \n",
        "    for r in range(MAX_STEPS):\n",
        "      #env.render()\n",
        "      \n",
        "      ###################################################\n",
        "      if (r%5==0 and r!=0):\n",
        "        screen = env.render(mode='rgb_array')\n",
        "        video.append(screen)\n",
        "      if (r%50==0) and (r!=0):\n",
        "        print(\"EPISODE :- \"+str(_ep)+\" STEP \"+str(r))\n",
        "        #plt.imshow(screen)\n",
        "        #ipythondisplay.clear_output(wait=True)\n",
        "        #ipythondisplay.display(plt.gcf())\n",
        "      ###################################################\n",
        "      state = np.float32(observation)\n",
        "\n",
        "      action = trainer.get_exploration_action(state)\n",
        "      # if _ep%5 == 0:\n",
        "      # \t# validate every 5th episode\n",
        "      # \taction = trainer.get_exploitation_action(state)\n",
        "      # else:\n",
        "      # \t# get action based on observation, use exploration policy here\n",
        "      # \taction = trainer.get_exploration_action(state)\n",
        "\n",
        "      new_observation, reward, done, info = env.step(action)\n",
        "\n",
        "      # # dont update if this is validation\n",
        "      # if _ep%50 == 0 or _ep>450:\n",
        "      # \tcontinue\n",
        "\n",
        "      if done:\n",
        "        new_state = None\n",
        "      else:\n",
        "        new_state = np.float32(new_observation)\n",
        "        # push this exp in ram\n",
        "        ram.add(state, action, reward, new_state)\n",
        "\n",
        "      observation = new_observation\n",
        "\n",
        "      # perform optimization\n",
        "      trainer.optimize()\n",
        "      if done: break\n",
        "\n",
        "      # check memory consumption and clear memory\n",
        "      gc.collect()\n",
        "      # process = psutil.Process(os.getpid())\n",
        "      # print(process.memory_info().rss)\n",
        "    ############################################################\n",
        "    if _ep!=0 and _ep%int(MAX_EPISODES/quiero_n_videos)==0:\n",
        "      \n",
        "      file_name_temp=file_name+str(num_video)\n",
        "      file_name_temp.replace(\" \", \"\")\n",
        "      print(\"DDPG: Vamos a generar el video\"+file_name_temp+\".mp4\")\n",
        "      generate_video(video,file_name_temp)\n",
        "      print(\"DDPG: Vamos a borrar el video\"+file_name_temp+\".mp4\")\n",
        "      deleter(len(video))\n",
        "      try:\n",
        "          files.download(\"/content/\"+file_name_temp+\".mp4\")\n",
        "          print(\"DDPG: Descargando...\")\n",
        "      except:\n",
        "          print(\"DDPG: No se pudo descargar correctamente, hágalo manual\")\n",
        "          pass\n",
        "    if _ep%100 == 0:\n",
        "      #trainer.save_models(_ep)\n",
        "      #trainer.save_models(_ep)\n",
        "      print(\"DDPG: debería guardar el modelo\")\n",
        "    num_video+=1\n",
        "    ############################################################\n",
        "  print ('DDPG: Todos los episodios finalizados, ya se debería',\n",
        "         'haber descargado todos los videos')\n",
        "  env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UYyfjOk_PGp",
        "colab_type": "text"
      },
      "source": [
        "# Generar video en Buffer para descargar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0ekLHhUEU7",
        "colab_type": "code",
        "outputId": "3a1a19dd-4de0-444a-df8b-42cc1a040e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Generar video\n",
        "from google.colab import files\n",
        "\n",
        "iniciar=1\n",
        "if iniciar==1:\n",
        "  file_name=input(\"Ingrese nombre del archivo que desea generar:\")\n",
        "  #if file_name==0: file_name=\"vid\"\n",
        "  print(\"El archivo se llamará \"+file_name+\".mp4\")\n",
        "  print(\"Ejecutando el algoritmo ...\")\n",
        "  ######################################################\n",
        "  \n",
        "  # algoritmos disponibles\n",
        "  # -heuristic(file_name)\n",
        "  # -ddpg(file_name)\n",
        "  ######################################################\n",
        "  \n",
        "else:\n",
        "  print(\"Cambia la variable iniciar a 1 no olvides elegir el método\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ingrese nombre del archivo que desea generar:ga\n",
            "El archivo se llamará ga.mp4\n",
            "Ejecutando el algoritmo ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmXiKzM6UF7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ddpg(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}